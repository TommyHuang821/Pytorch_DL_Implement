{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度學習\u000b",
    "Pytorch手把手實作-資料庫: Data loader example by pytorch \n",
    "\n",
    "### 此部分我們先介紹\n",
    "<br>**<font color = blue size=4 face=雅黑>I. 當dataset是torch vision提供的寫法</font>**<br/>  \n",
    "<br>**<font color = blue size=4 face=雅黑>II. 當dataset是私有資料庫的寫法。</font>**<br/>  \n",
    "<br>**<font color = blue size=4 face=雅黑>III. 如何將資料丟到CUDA</font>**<br/>  \n",
    "\n",
    "--------------------\n",
    "\n",
    "**<font color = blue size=6 >I. 當dataset是torch vision提供的寫法。</font>**\n",
    "#### Dataset loading方式見 01_database_pytorch.ipynb\n",
    "Dataset loading是利用torch內建的函數(torch.utils.data.DataLoader)將資料庫放到pytorch的data loader內。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "dataset_MNIST = datasets.MNIST('./dataset', train=True, download=False)\n",
    "# 利用torch內建的函數將資料庫放到pytorch的data loader內。\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們看一下這個函數定義完後得結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnistdata_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我們要怎麼繼續使用這個torch dataloader來進行學習?\n",
    ">直接用for loop指派即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-08026b35b7e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmnistdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
     ]
    }
   ],
   "source": [
    "for data, target in mnistdata_loader:\n",
    "    print(data)\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**<font color = red size=4 >咦~~~~~ 上面程式怎麼掛了</font>**<br/>  \n",
    "\n",
    "<font color = black size=3 >我們看一下錯誤訊息</font>\n",
    "\n",
    "\n",
    "<font color = red size=3 >「TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>」</font>\n",
    "\n",
    "看起來就是資料格式出錯了，我們輸出的資料是PIL image格式。<br>\n",
    "\n",
    "<br> **<font color = black size=4 > 要讓torch.utils.data.dataloader.DataLoader運作的方式dataset輸出的資料必須是 tensors, numpy arrays, numbers, dicts or lists</font>**<br/> \n",
    "\n",
    "所以我們check看看dataset_MNIST的輸出是什麼？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x2B6FC124708>, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(dataset_MNIST.data[0,:,:]))\n",
    "dataset_MNIST.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然 dataset_MNIST.data 可以看到所有的data，而且是torch.Tensor的格式\n",
    "\n",
    ">**實際上torch的dataloader是看dataset結構內的.__getitem__的輸出 (自定義資料庫的時候會介紹怎麼撰寫)**\n",
    "\n",
    "所以 dataset_MNIST讀取到的資料其實是**PIL.Image.Image**。\n",
    "\n",
    "\n",
    "<br> **<font color = red size=3>Question:</font>** 這時候我們要怎麼改讓資料可以順利執行?<br/>\n",
    "<br> **<font color = red size=3>ANS:</font>**  格式不對就改格式就好了<br/>\n",
    " \n",
    " trochvision內提供了function，只需要搭配torchvision.transforms的ToTensor()即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.ToTensor()\n",
    "dataset_MNIST_tensor = datasets.MNIST('./dataset', train=True, download=False, transform=transform)\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**所以當格式經由torch vision提供的transforms.ToTensor()，可以將資料成功轉換成 torch.tensor，這時候就可以順利跑資料的forloop了。**\n",
    ">這邊稍微注意一下，我們batch_size設定為2，所以出來的資料會有兩筆，我們在print size時候可以看到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations: 30000\n",
      "torch.Size([2, 1, 28, 28])\n",
      "torch.Size([2])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "tensor([6, 8])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for data, target in mnistdata_loader: \n",
    "    count+=1\n",
    "print(\"total iterations: {}\".format(count))\n",
    "print(data.size())  # batch * channel * h * w\n",
    "print(target.size()) # batch\n",
    "print(data)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**因為batch size設定是2，MNIST資料有60000筆資料，這樣一個iteration跑2張圖，所以要跑30000次才能將整個資料集都跑完(一個epoch)，因此整個for loop需要執行30000次。**<br>\n",
    "我們測試將batch size設定是200，這樣iteration次數應該是60000/200=300次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations: 300\n"
     ]
    }
   ],
   "source": [
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=200, shuffle=True)\n",
    "count = 0\n",
    "for data, target in mnistdata_loader:\n",
    "    count+=1\n",
    "print(\"total iterations: {}\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**<font color = green size=5> Shuffle的設定</font>** <br>\n",
    "**<font color = black size=3> 當 Shuffle = False</font>**<br>\n",
    "見下面結果，可以發現兩個for loop得到的batch資料結果是**<font color = red >一樣的</font>**。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first epoch\n",
      "tensor([5, 0])\n",
      "Second epoch\n",
      "tensor([5, 0])\n"
     ]
    }
   ],
   "source": [
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=2, shuffle=False)\n",
    "print(\"first epoch\")\n",
    "for data, target in mnistdata_loader:\n",
    "    print(target)\n",
    "    break\n",
    "print(\"Second epoch\")\n",
    "for data, target in mnistdata_loader:\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = black size=3> 當 Shuffle = True</font>**<br>\n",
    "見下面結果，可以發現兩個for loop第一次得到的資料結果是 **<font color = red >不一樣的</font>**。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first epoch\n",
      "tensor([5, 1])\n",
      "Second epoch\n",
      "tensor([9, 7])\n"
     ]
    }
   ],
   "source": [
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=2, shuffle=True)\n",
    "print(\"first epoch\")\n",
    "for data, target in mnistdata_loader:\n",
    "    print(target)\n",
    "    break\n",
    "print(\"Second epoch\")\n",
    "for data, target in mnistdata_loader:\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**要避免每一個epoch都學習一樣的順序和一樣的batch時候Shuffle就需要設定為True** <br>\n",
    "\n",
    "這樣資料在每一次for loop(每個epoch)的時候，每個batch的組合都會重新打亂，這樣learning model過程中可以避免每個epoch學習都是在學習固定的pattern。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------\n",
    "**<font color = green size=5> num_worker的設定</font>** <br>\n",
    "num_worker: 用來進行平行運算的CPU數量。每個數量會去處理不同的batch data。\n",
    "\n",
    "運作模式: <br>\n",
    "假設我們的資料有三個batch，batch 1, batch 2, batch 3。<br>\n",
    "當num_worker=0，CPU會batch 1處理好在繼續處理batch 2，batch 2處理好在繼續處理batch 3。 (**下圖上**)<br>\n",
    "當num_worker=3，CPU會開三條平行運算的線，第一條處理batch 1，第二條處理batch 2，第三條處理batch 3(**下圖下**)。<br>\n",
    "<img src=\"Image/parallel.png\"  width=\"40%\">\n",
    "\n",
    "下面我們測試不同num_workers會有什麼差異。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:2\n",
      "batch_size:10\n",
      "batch_size:100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEXCAYAAACjyo8UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhU5dn48e+dyUYgCYSQkBBIwk7YAgmgYkVUUEAQ11Yt1datVlv9qbW29X1rW+zytqWI2hb7WrFa7FsRUVxaNkHc2JEdkpCwk4UISYCELM/vj5lACEwySebMcnJ/rmuuzJwz55wb7uSeM895zvOIMQallFL2FeLvAJRSSllLC71SStmcFnqllLI5LfRKKWVzWuiVUsrmtNArpZTNBX2hF5ECEbnGB8d5RkRe98J+/iIi/+WNmOxGc2kPmsfAE/SFvi1EZKWI3OvLYxpjvmuM+aU39ykiPxSRbSJSLiL5IvJDb+4/GNgol+NF5CMROSEiBRdZn+Zaf0pEdvmioPqS5vHs+v8nIkdd2/9NRCLaEk+7LvQ2IsC3gC7AdcDDIvIN/4akWukk8DfA3Yf1G8AmoCvwU2CBiHTzUWzKc63Oo4hcCzwFXA2kAb2Bn7cpGmNMUD+AAuDHwA7gK+AVINK1rgvwHlDsWvcekOJa9yxQC1QCFcALruWDgaVAKVAI/MS1/BngX8DfgXJgO5DtJiYB/ggUASeALcAQ17p5wEzX88WuY9c/6oC7XesGNohjN3BbC/5P5gDP+zs3msvW5xK4BihotKw/UAVEN1i2Gviuv3OnefReHoH5wK8arLsaONqmnPj7l8JLv1TbgJ5AHPBpg6R1BW4GooBo4E1gUYNtVwL3NngdDRwBHgciXa/HNPilqgQmAw7g18AXbmK6FtgAdHb9gg0Ckhr/UjXa5jrgsOvf0RE4AHwbCAVGAiXAYNd77wC2NPELvYkA++PXXLYsl1y8QNwI7Gy07AUC7ENd89i2PAJfAl9vsC4eMEDX1ubELk03LxhjDhhjSnGeFdwOYIw5Zox5yxhzyhhT7lo3ron9XI/zk/MPxphKY0y5MWZNg/WfGGM+MMbUAq8Bw93spxrnL+RAQIwxO40xR9wdVET64zwr+box5oArjgJjzCvGmBpjzEbgLeAW179rvjFmmJvdPYOzSe6VJv6dgUxz6V4nnGejDZ1wxRdoNI/uNZfHxuvrn7c6z3Yp9AcaPN8HJAOISJSIzBWRfSJSBnwMdBYRh5v99ATymjjO0QbPTwGRIhLa+E3GmBU4P6FfBApF5CURibnYDkUkFngH+C9jzGrX4lRgjIgcr38AdwLdm4gNEXkYZ1v9FGNMVVPvDWCaS/cqgMbHjsHZbBFoNI/uNZfHxuvrn7c6z3Yp9D0bPO+F8+sWOL/uDcD5VS8GuMK1XFw/Gw/deQDo442AjDFzjDFZONsX+3ORizIiEoKzPe4jY8zcRnGsMsZ0bvDoZIx50N3xROQ7uC7gGGMOeuPf4CftPpdN2A70FpGGZ3bDXcsDjebRvebyuJ3zv5kMBwqNMcdacSzAPoX+IRFJEZE44CfA/7mWRwOngeOudT9rtF0hziva9d4DuovIoyISISLRIjKmpcGIyCgRGSMiYTivvlfivMjU2LM42/4eabT8PaC/iMwQkTDXY5SIDHJzvDuBXwETjDF7WxpvgGnvuQwRkUggzPlSIkUkHMAYswfYDPzMtfxGYBjOJoRAo3lsfR7/DtwjIhki0gV4Gud1hNZrbeN+oDw4/wr/ceBVIMq1LhnnxZ0KYA/wAM4zhlDX+ktdy78C5riWDQGWu5YdBZ4y5y78vN7guGkN99UopqtxXtWvwHnB5h9AJ9Powo8r9voeBvWPO13rBgDv4+ydcAxYAWS61t0JbG9wvHycbZAN9/MXf+dGc9mqXF7piqXhY2WjWFfiLJa7gWv8nTfNo/fzCDyG80OvDOf1toi25ERcO1VKKWVTdmm6UUop5YZlhV5EBojI5gaPMhF51KrjKd/QvNqT5tXefNJ04+o6dQjnlfZ9lh9Q+YTm1Z40r/bjq6abq4E8/aWxHc2rPWlebeaCGwss8g2cg/hcQETuB+4H6NixY9bAgQNbdYCaWsPOo2Ukx3aga6dwj7YxBrYfPkHXThEkxUa26rh2tGHDhhJjjCcDZVmeV+U9mld78iSvljfduPqOHsY5JkRhU+/Nzs4269evb9VxPs0t4c7/XcM/7h3D2L7xHm93218+p6qmlncevrxVx7UjEdlgjMlu5j0+yavyHs2rPXmSV1803UwCNjb3S9NWuUUVAPRL6NSi7Uald2Hb4TJOVtVYEZad+SSvyuc0rzbki0J/O26+BnpTTlE50ZGhdItu2fj8o9O7Ultn2LT/uEWR2ZZP8qp8TvNqQ5YWehGJAiYAC608DjjP6PsldEJEmn9zAyN7dSZEYG1+q4eRaHd8mVflO5pX+7L0Yqwx5hTO8actl1tUwVUDE1q8XXRkGBnJMawtKLUgKnvyZV6V72he7csWd8Z+dfIMJRVn6JfQuuGaR6XFsWn/cc7U1Hk5MqWU8j9bFPrcYueF2L4tvBBbb0x6HFU1dWw91HguAKWUCn72KPRFbSv02WlxAKzN1+YbpZT92KbQdwhz0KNzh1ZtH98pgt7dOrJO2+mVUjZki0KfU1RB724dCQlpWY+bhsakx7GuoJTaOh22WSllL7Yo9HmurpVtMSotjvLKGnYfDcTpN61TVFbJbXM/p6i80t+hKKUsEvSF/mRVDYeOn251+3y9Ua52+vbWfDNneQ7rCkqZsyzH36EopSziq0HNLJN3tsdN67pW1kvp0oGk2EjWFpRy12VpXogssA14+kOqGnQnfX3Nfl5fs5+I0KD/7FdKNRL0f9U5hW3rcVNPRBidHse6/FLaw/SKv7tlGFHhjrOvI8NCuCEzmdU/Gu/HqJRSVgj6Qp9bXEGYQ0jtGtXmfY1Ki6OovIp9x055IbLAVHryDI/932Z+8M/NOEQQICI0hKqaOqIjQkmI1uGalbKboG+6ySmsIK1rR8Icbf/MGp3u6k9fUEpafMc27y+QGGN4Z/NhfvHeDspOV/P9q/qy80gZ3WM7cMfoXsxfu59ivSCrlC0FfaHPK65gUFLb2ufr9e3Wic5RYazLL+W27J5e2WcgOFB6ip8u2sbHe4rJ7NmZ39w8lIHdY857z8zpQ/wUnVLKakFd6Ktqatl37CRThyV5ZX8hIcKotDjb9Lypqa1j3mcF/GHJHkTgZ1Mz+NalaTjacL+BUir4BHWhzy85SZ2BPm28ENvQ6LQ4lu4opKiskoSY4G2v3n74BE+9tZWth05w1cAEfjl9SKvvHFZKBbegvhh7blYp7zTdAIxq0E5vBatvUKqsruU3H+5i2gufcuTEaZ6/fQQv35WtRV6pdiyoC31OYQUi0Lub9y6cDk6OISrcwTqLBjiz8galT3NLuHb2x/xlVR43j+zBssfGMXV4cosnY1FK2UtQN93kFlfQKy6KyDBH82/2UJgjhJG9urDGy4W+qRuUds+c1KZ9Hz91hmff38mbGw6S2jWK+feO4bIWTJCulLK34C70hRX07ea99vl6o9LimL18DydOVxPbIcwr+1z95Hi+M28d2w6Xnbc81CFc//xqesVF0TMuil5xUaTGdaRXXBTJnSMJddNttKiskoff2Mi04T2YvWwPX52q5sEr+/DI1f28+sGnlAp+QVvoa2rryC85yZUDu3l936PSu2AMbNhXylUDE72yz9U5JWeLfLhDqK41jOzVmcE9YtlfeopdR8pZuqOQ6tpzd+U6QoQenTuc/RBI7er8IOgVF8XcVXmszf+KtflfMSwllle/M5rBybFeiVUpZS9BW+j3l57iTG2dJWf0I3p2IcwhrM3/yiuFfumOQp58awtxHcO4dnB3ZlySdvYGpV/ccK7/em2dobCskn3HTnGg9BT7S0+xz/XzP9uPUnryzEX3v+XgCW7602dtbgJSStlT0Bb6sz1uEr3X46Zeh3AHQ3vEsjb/WJv39XneMR6av5EhyTH8475L6BTh/C+/2A1KjhAhuXMHkjt34NI+F87RXFZZzZcHjjNneQ6bDxynutYQGRbCtYO789Mpg9ocq1LKnoK21039PLF9vNjjpqFR6XFsPXSCyuraVu9j68ET3Pf39aTGRTHv26PPFvnWiokM42v9utE/MZqaOqNj1CilPBK8hb6wgu4xkURHeudiaWNj0uOorjVs2n+8VdvnFlVw1ytrie0Qxmv3jKFLx3CvxVZSUcWdY1J5+3tjuXNMKsUVVV7bt1LKfoK36aa4gn6J3m+fr5eVGoeIcyKSizWjNOXQ8dN86+U1hAi8fu8Yusd692x77ozss891jBqlVHOC8oy+rs6QW1RBHwsuxNaL7RDGgMRo1rawP/2xiipmvLyG8qoaXv3OaNJtNgqmUir4BGWhP1JWyakztZae0YNz2OKN+7+iprau+TcD5ZXV3PXKWg4fP83f7h6l3R2VUgEhKAt9TqFzAm8rulY2NDo9jlNnatne6Cani6msruXeV9ez60g5f74z6+wctEop5W9BWeit7FrZ0GhXsW6u+aa6to6H529kbUEpf7htOOMHJlgal1JKtUTQFvq4juHEebEny8UkxESS2jWqyZEs6+oMP1qwhWU7i/jFDUO4IbOHpTEppVRLBW2hb+tk4J4alRbH+oJS6uounDDcGMMv3tvBwk2HeGJif2ZckuqTmJRSqiWCrtAbY8jxYaEfnR7HV6eqyXPdoNXQnOW5zPusgHsuT+eh8X19Eo9SSrVU0BX6kooznDhdbfmF2Hr17fSNhy2e92k+f1y2h1uyUvjp5EE65rtSKmAFXaE/dyHWN4U+tWsU3aIjzptHdtGmQzyzeAcTMxL5zU1DCdE5WJVSASwIC72ra6WPmm5EhNHpcWdnnFq+s5DH3/ySS3t3Zc7tI9yOF6+UUoEi6IZAyC2qoFNEKN19OHH36LQ43t9yhKv+sJKDpacYkhzDX+/K1gk+lFJBwdLTURHpLCILRGSXiOwUkUvbus+cogr6JHTyaZt4/c1Pe4tPEhnm4BUvjEQZzKzIq/I/zat9WV2tngP+bYy5RUTCgai27jC3qIIr+nt/Vil3Gs/1WlZZw8hfLvXKXK9BzOt5VQFB82pTlp3Ri0gMcAXwMoAx5owxpnVj/rqcOF1NUXmVz9rnwTnX67TMZCJCnf9VkWEh3JCZzOofjfdZDIHEirwq/9O82puVTTe9gWLgFRHZJCL/KyIXDOUoIveLyHoRWV9cXNzkDs/2uPFhoU+IiSQ6IpQztXU60YeT1/OqAoLm1casLPShwEjgz8aYEcBJ4KnGbzLGvGSMyTbGZHfr1nSTTJ6r0PvyjB50oo9GvJ5XFRA0rzZmZRv9QeCgMWaN6/UCLvKL0xI5ReWEh4aQ0sW3TYc60cd5vJ5XFRA0rzZm2Rm9MeYocEBEBrgWXQ3saMs+6ycbcegNSn5jRV6V/2le7c3qXjffB/7huoK/F/h2W3aWU1TBiF5dvBKYahOv5lUFDM2rTVla6I0xm4HsZt/ogVNnajh0/DS3Zff0xu5UG3gzrypwaF7tK2ju399bfBJjfH8hVimlgl3QFHp/dK1USik7CJpCn1NUjiNESO16QddepZRSTQiaQp9bVEFa1yjCQ4MmZKWUCghBUzV9OX2gUkrZSVAU+jM1dRQcO6WFXimlWiEoCv2+YyeprTP0S4j2dyhKKRV0gqLQ5/hpjBullLKDoCj0uUUViEAfH00IrpRSdhIUhT6nqIIenTvQIVyn7lNKqZYKikKfW1ShN0oppVQrBXyhr60z5BVr10qllGqtgC/0B786xZmaOu1xo5RSrRTwhb5+jJs+ekavlFKt0uQwxSISCVwPfA1IBk4D24D3jTHbrQ9Pu1ZaobKykvfee4/Vq1dz+PBhOnTowJAhQ5gyZQqDBw/2d3iqDZrKrWq/3BZ6EXkGmAqsBNYARUAk0B/4jetD4HFjzBYrA8wtqiAhOoLYDmFWHqbdeOaZZ1i8eDFXXnklY8aMISEhgcrKSvbs2cNTTz1FZWUlQAd/x6larrncAv1EZJjVf7Mq8DR1Rr/OGPOMm3WzRCQB6OX9kM6Xo2PceNWoUaN45plnLrruscceo6ioiMTERJ2rMQg1l1sRyQfCfRqUCghu2+iNMe83XiYiISIS41pfZIxZb2VwxhjytGulV13sK3xdXR1lZWUAJCQkAJzybVTKG5rLLVBj9d+sCkzNXowVkfkiEiMiHXFOFrxbRH5ofWhwtKySiqoaPaO3wB133EFZWRknT54kIyODAQMG8Lvf/c7fYSkv0NyqxjzpdZNhjCkDpgMf4GyumWFpVC65Zy/EatdKb9uxYwcxMTEsWrSIyZMns3//fl577TV/h6W8QHOrGvOk0IeJSBjOQv+OMaYaMNaG5ZRTqD1urFJdXU11dTWLFi3ihhtuICwsDBFtmrcDza1qzJNCPxcoADoCH4tIKlDW5BZekltcQeeoMOI76fUjb3vggQdIS0vj5MmTXHHFFezbt4+YmBh/h6W8QHOrGhNjWnZyLs5TA4cxpsbbwWRnZ5v1689dK7pt7ufU1RkWPHiZtw+lGjHGUFtbS2hoKCKywRiT7a19N86r8q363IaFhWlebciTv1e3Z/Qi8k0RuWC9caoRkT4icrk3AnVHpw/0vtdff526uroLlosIoaGh5OXlAeh/ehBqLrdAhNV/syowNdWPviuwSUQ2ABuAYpw3TPUFxgElwFNWBXasoorSk2e00HvZsWPHGDFiBFlZWWRlZdGtWzcqKyvJzc1l1apVxMfHA1T7O07Vcs3lFkgBCv0cpvKDpvrRPweMBN4AugFXu14fAmYYY242xuRYFdi6glIA4jtFWHWIdumRRx5h48aN3H777RQXF7N8+XI2btxIjx49eO2113jrrbcAqvwdp2q55nIL5Fn5N6sCV5Nj3RhjaoGlrodP/e3TAgBW7Sli+ogevj68rTkcDiZMmMCECRP8HYryMs2tupgmC70/DHj6Q6pqzrUzvr3pMG9vOkxEaAi7Z07yY2RKKRWcAm6Y4tVPjmdaZjIhrm6/kWEh3JCZzOofjfdvYEopFaQCrtAnxEQSHRGKAcIdIVTV1BEdEUpCdKS/Q1NKqaDkyVg3iSLysoh86HqdISL3WBlUSUUVd45JZdFDY7lzTCrFFXpt0NsKCwu55557mDTJ2Ry2Y8cOXn75ZT9HpbxBc6sa8+SMfh7wH5wTjwDsAR61KiCAuTOymTl9CBnJMcycPoS5M7x2j4dyufvuu7n22ms5fPgwAP3792f27Nl+jkp5g+ZWNeZJoY83xvwLqANw3RFba2lUynIlJSXcdttthIQ4fwVCQ0NxOBx+jkp5g+ZWNeZJoT8pIl1xDWQmIpcAJyyNSlmuY8eOHDt27OxgV1988QWxsbF+jkp5g+ZWNeZJ98rHgHeBPiLyKc6bp27xZOciUgCU4/wGUOPNcTZU28yaNYtp06aRl5fH2LFjKS4uZsGCBR5tq3kNbO5yO3z48Ca307zaV7OF3hizUUTGAQMAAXa7hir21HhjTElrA1TWGDlyJKtWrWL37t0YYxgwYABhYS2al1fzGqDamFvNqw01W+hFxAFMBtJc758oIhhjZlkcm7JQbW0tH3zwAQUFBdTU1LBkyRLAObeoCm7ucqvaL0+abhYDlcBWXBdkW8AAS0TEAHONMS81foOI3A/cD9Crl+VzjSuXqVOnEhkZydChQ89etGsBzWsAa0NuNa92ZYxp8gFsae49TWyb7PqZAHwJXNHU+7OysozyjaFDh7pdB6w3mteg5S63mld7ai6vxhiPet18KCITW/khctj1swh4Gxjdmv0o75s0aVKrv9JrXgNba3OrebUvTwr9F8DbInJaRMpEpFxEmp1KUEQ6ikh0/XNgIrCtbeEqb7nkkku48cYb6dChAzExMURHR3s03ZzmNfC1JreaV3vzpI3+D8ClwFbX1wRPJeL8gKg/znxjzL9bHqKywuOPP87nn3/O0KFDWzpxtOY1wLnLbTN51rzamCeFPgfY1sIijzFmL9B0x13lN/369WPIkCEtLfKa1yDQmtxqXu3Nk0J/BFjpGtTs7OhiRrtXBrWkpCSuvPJKJk2aRETEuVm8tHtl8HOXW9V+eVLo812PcNdD2UB6ejrp6emcOXOGM2fO+Dsc5UWaW9WYtLBFxlLZ2dlm/fr1/g6j3RORDcaLt79rXgOD5tWePMmr2zN6EZltjHlURBbjGtCsIWPMNC/EqHzs0UcfZfbs2UydOvWibbjvvvuuH6JS3tBcblX71VTTzWuun7/3RSDKN2bMmAHAE0884edIlLc1l9vFixf7MhwVQNwWemPMBtfTTGPMcw3XicgjwCorA1PWyMrKAmDz5s088sgj56177rnnGDdunD/CUl7QXG5V++XJDVN3XWTZ3V6OQ/nYq6++esGyefPm+T4Q5XWaW9VYU230twN3AOki0rDhNho4ZnVgyhpvvPEG8+fPJz8/n2nTzl1mKS8vp2vXrn6MTLWV5la501Qb/Wc4+9DH47w7tl45sMXKoJR1LrvsMpKSkigpKeHxxx8/uzw6Opphw4b5MTLVVs3ltoXzDSgbaaqNfh+wD+fwB8omUlNTSU1N5fPPP/d3KMrLNLfKnRYPRK6UUiq4aKFXSimba7bQu7pSNrtMBZeLdbfTLnj2oLlVjWn3ynZKu+DZl+ZWNabdK9sZ7YJnX5pb5Y52r2xntHulfWn3SuWOdq9sZ7QLnn1pbpU7nlyMvUlEckTkREvmjFWBbeHChfTr14/Y2NgWzRmrAp/mVjXmycQj/wNMNcbstDoY5TtPPvkkixcvZtCgQf4ORXmZu9zq0MXtlye9bgq1yNtPYmKiFnmb0tyqxjw5o18vIv8HLOL8OWMXWhaVslx2djZf//rXmT59+nnzit50002WHreorJKH39jEC3eMICE60tJjtVfucqvaL08KfQxwCpjYYJkBtNAHsbKyMqKioliyZMnZZSJieaGftXQP6/JLmbMsh5k3DrX0WO2Vu9yq9kvnjFUXsGJu0fLrfklVTd0F6yJCQ9g9c5K3DqWaoHPG2pMnefWk101/EVkuIttcr4eJyNPeClL5x549e7j66qsZMmQIAFu2bGHmzJmWHW/1k+OZlplMROi5X7mRvTqz+kfjLTtme+Xr3KrA58nF2L8CPwaqAYwxW4BvWBmUst59993Hr3/967M30QwbNox//vOflh0vISaS6IhQztTWEe4q9hv3H+fN9QcJpG+VduDr3KrA50mhjzLGrG20rMaKYJTvnDp1itGjR5+3LDTUk0s2rVdSUcWdY1JZ9L2x3DG6F0mxkfzuP7t5etE2amovbNZRreOP3KrA5kn2S0SkD84LsIjILTiHRlBBLD4+nry8vLMX6RYsWEBSUpKlx5w741wz4q9uGkpdneF3S3bz55V5FJZV8vztI+kQ7rA0hvbAXW6//PJLy46pvakCmyeF/iHgJWCgiBwC8oFvWhqVstyLL77I/fffz65du+jRowfp6em8/vrrPo0hJET40XUDSYqN5Gfvbuf2v37By3dl07WTdglsC3e5TU9Pt+yYc5bnsK5Ae1MFKo973YhIRyDEGFNuVTB6Fd/3Tp48SV1dHdHR0WeX+aN3xn+2H+UHb2wiKTaSV78zmtSuHb11+HarcW61N5U9eZLXZs/oRaQz8C0gDQit/zpojPmBF2JUfnL8+HH+/ve/U1BQQE3NuUsuc+bM8Us81w7uzvz7xnDPq+u56U+f8fLdo8js2dkvsQQ7d7m1wuonxzPzg538Z9tRqmrqCA0RpgxL4qdT9M7cQOJJ080HwBfAVkCvmNnE5MmTueSSSxg6dCghIYExo2RWahxvPXgZd7+ylttf+oIX7hjB1YMS/R1W0PFlbhv2pgoRqKkzhDtCtJ0+wHhS6CONMY9ZHonyqcrKSmbNmuXvMC7Qp1snFj44lu/MW8d9f1/PszcO5fbRvfwdVlBxl9u7777bkuPV96a6tHccD83fxIZ9pZYcR7WeJ4X+NRG5D3iP88e60WwGsRkzZvDXv/6V66+//rzxUOLi4vwYlVO36Aj+ef8lPDR/Iz9euJUjx0/z/yb019v4PeQut1Zp2Jvqg21H+WhXEccqqvSiegDx5HvdGeB3wOfABtdDr5gGufDwcH74wx9y6aWXkpWVRVZWFtnZXrtO12YdI0L567eyuS07hTkrcvnhgi1Ua197j/gzt//vmn5UVtcy9+O9Pjme8ownZ/SPAX2NMSVWB6N8Z9asWeTm5hIfH+/vUNwKc4Tw25uHkdy5A7OX5VBYVsmfv5lFpwi9+acp7nLri29EfROiuSGzB3//vIB7v5aubfUBwpMz+u04R69sFRFxiMgmEXmvtftQ3jd48GCioqJavb2v8ioiPHpNf35781A+yzvG1+d+TlFZJUVlldw293OKyiutPHxQaktuvZHXR67uR3Wt4U8f5bV2F8rLPDk1qgU2i8hHnN9G72n3ykeAnTiHO1YBwuFwkJmZyfjx489rx21B90qf5vXro3qREBPJQ//YyI1/+oyRvTrrDTpuuMuth9qc17T4jtw8sgfz1+zngXG9SYrt0NpdKS/xpNAvcj1aTERSgCnAszibgFSAmD59OtOnT2/Vtv7K6/gBCVTX1nHo+GkOHT8NwOtr9vP6mv16g04Drc2tN/P6/av68famQ7ywIpdn9YPY75ot9MaYV0WkA9DLGLO7hfufDTwJRLt7g4jcD9wP0KuXdqPzlbvuuovTp0+zf/9+BgwY0NLN/ZbXT390FT95eyvLdxZhgMiwEK4d3F1v0GnAXW496F7ptbz2jIvi66N68s+1B/juuD70jGt9M6FqO0/Go58KbAb+7XqdKSLverDd9UCRMWZDU+8zxrxkjMk2xmR369bNw7BVWy1evJjMzEyuu+46ADZv3sy0adOa3c7feU2IiSQx5twFvqrqOqIjQvWiXwOtya0VeX14fD9CQoQ5y3Na9g9QXufJxdhngNHAcQBjzGbAk9GRxgLTRKQA+CdwlYj4dtQs5dYzzzzD2rVr6dzZOcxAZmYm+fn5nmzq97yWVBeosNsAABm6SURBVFRxa3YKDoFBydEUV1Q1v1E70srcej2v3WMjuXNMLxZuOkR+ycm27Eq1kSeFvsYYc6LRsmZHQjPG/NgYk2KMScM5UckKY4yOehkgQkNDiY2NPW+ZJ93vAiGvc2dk8z+3DOfSPvFUVtedd8OOal1urcrrg1f2IcwhPLdsT1t3pdrAk0K/TUTuABwi0k9Engc+szguZbEhQ4Ywf/58amtrycnJ4fvf/z6XXXaZv8NqkQkZiewtPklecYW/QwkogZTbhOhI7ro0jXe+PExOoWUD36pmeFLovw8Mxtm18g2gDHi0JQcxxqw0xlzf8vCUVZ5//nm2b99OREQEt99+OzExMcyePbtF+/B3XidkOAc8W7qj0F8hBKS25tbbeX1gXB+iwhzMXqZt9f7i8Xj0vqDj0QcGf4xH31rXP7+acEcIC7831pL924k/8/qHJbt5fkUuH/zga2Qk6y013tSm8ehFZDFNtMUbY5rvoqECztSpU5tsr3333WY7VAWUCYO6M3v5HorLq+gW3b4H0Wout/507+W9mfdZAbOW7uF/79JrKr7WVD/63/ssCuUzTzzxhL9D8KoJGYn8cdkelu8s5BvtfDjj5nK7ePFiH0VyodioMO77Wm9mLd3DlweOM1wnlfEpt4XeGLOq/rmIhAMDcZ7h7zbGnPFBbMoC48aNO/v8zJkz7Nq1CxFhwIABhIeH+zGy1hmUFE1Klw4s3aGFPtBz++2xafzt03xmLd3Dq98Z7e9w2hVPphKcAvwFyAMESBeRB4wxH1odnLLO+++/z3e/+1369OmDMYb8/Hzmzp3LpEnBNYyAiDAhI5F/rNnPyaoaOurIlm5z62/RkWE8cEUffvvvXWzYV0pWqv/nPmgvPPmr+AMw3hiTCyAifYD3AS30Qezxxx/no48+om/fvgDk5eUxZcqUoCv04Gy+eeXTAlbnFHPdkCR/h+N37nIbCO66LJWXP9nLH5bsYf59l/g7nHbDk+6VRfVF3mUvUGRRPMpHEhISzhYCgN69e5OQkODHiFpvdFocsR3CWKLdLIHAzm1UeCgPXtmXz/KO8XneMX+H0254cka/XUQ+AP6Fs43+VmCdiNwEYIxZaGF8yiKDBw9m8uTJ3HbbbYgIb775JqNGjWLhwoUAQXWlLNQRwtUDE1ixq4ia2jpCHYEx2bm/uMvt6tWrO4vITf7+m71zTC9e+jiPWUt386/elwZsTyE78eQvIhIoBMYBVwLFQBwwFdCboIJUZWUliYmJrFq1ipUrV9KtWzdKS0vre2YEVaEHZ/PN8VPVrCv4yt+h+J273OLMq9//ZiPDHDw8vi/rCr7i4xyduM4X9IYpdYFgumGq3smqGkb8cinfHJPKf0/NsPRYwSqQ8lpVU8tVv19FfKdwFj00Vs/q26BNN0w12Ek6zmEQ0hq+X2+YCm75+fk8//zzFBQUUFNTc3Z5sN0wVa9jRCiX941n6c6j/Nf1g9p14XCX20ASEerg+1f15amFzrkFrnENZ6Gs4ekMUy8Di4E6a8NRvjJ9+nTuuecepk6dSkiIPdq0J2QksmJXEbuOljMoqf3eZu8ut/68Yepibs5K4U8r85i1dA9XDUwgJKT9fjhbzZNCX2mM8XgiURUcIiMj+cEPPJ32NzhcPSgBEecgZ+250AdLbsMcITx6TT8e+9eX/Gf7USYN1a6xVvGk0D8nIj8DlnD+5OAbLYtKWe6RRx7h5z//ORMnTjxvAumRI0f6Maq2SYiOZETPzizdUcgPru7n73D8xl1uA9ENmT148aNc/rhsDxMHd8ehZ/WW8KTQDwVmAFdxrunGuF6rILV161Zee+01VqxYcfbrvYiwYsUKP0fWNhMyuvPbf+/i8PHTJHfu4O9w/MJdbgORI0R49Jr+fP+NTby35TA3ZPbwd0i25EmhvxHorePb2Mvbb7/N3r17A2IMFG+akJHIb/+9i2U7C/nWpWn+Dscv3OU2UIv9lKFJvPhRLrOX5TBlaFK7vw/CCp78j35JEParVk0bPnw4x48f93cYXtc3oRO94zu268lIgi23Ia6z+vySk7y96ZC/w7ElT87oE4FdIrKO89votXtlECssLGTgwIGMGjXqvHbcYO1e2dCEwYm8vDqfE6erie0Q5u9wfM5dbgPZtYMTGdIjhj8u28O/1h/gxTtHkhAd6e+wbMOTQv8zy6NQPvfzn//c3yFYZmJGInNX7WXl7qJ22ebrLreB1r2yIRHh8QkD+Pa8dRw5XsmcZTnMvHGov8OyjWYLfcNx6ZV9NBy73G4ye3YhvlM4S3cUtstCH4y5HfD0h1TVOPt6GOD1Nft5fc1+IkJD2D0z+EZUDTRu2+hF5BPXz3IRKWvwKBeRMt+FqLzp8ssvByA6OpqYmJizj/rXduAIEa4ZlMiq3cWcqWk/9/gFc25XPzmeaZnJhDucF4zDHcINmcms/tF4P0dmD03NMHW562e078JRVvvkk08AKC8v93Mk1pqQkcg/1x3gi73HuKJ/N3+H4xPN5TZQe90AJMREEh0RSnWdc+ytM7WG6IhQbaf3Eu3HpGxpbN94OoQ5WLLjqL9DUR4qqajizjGp3JiZjACHjp/2d0i2ofOuKVuKDHMwrn83lu0o4pc3mIA+m1VOc2c4B2DcdbSMtzcfZlw7+SbmC3pGr2xrQkYiR8sq2XrohL9DUS0wsHsMQ3vE8uaGg/4OxTa00CvbumpgAo4Qadc3TwWrW7JS2H64jB2Htd+HN2ihV7bVpWM42aldWLJdC32wmTY8mTCH8NZGPav3Bi30ytYmDu7O7sJy9h875e9QVAt06RjONYMSWbTpENW17aeLrFW00Ctbm+iauUh73wSfW7NTOHbyDB/tKvJ3KEFPC72ytZ5xUQzsHs0SbacPOlf060Z8pwgW6EXZNtNCr2xvYkYi6wtKKT2pI20Hk1BHCDeN7MGKXUUcq6hqfgPllhZ6ZXsTMrpTZ2CFNgEEnVuyUqipM7yz+bC/QwlqWuiV7Q3pEUNSbCRLtZ0+6PRPjGZ4ivapbyst9Mr2RJyDnH28p4TK6lp/h6Na6JasFHYeKWP7Yb3xrbUsK/QiEikia0XkSxHZLiL2HQC9HQnWvE4cnMjp6lo+ySnxdygBKZDzOnV4MuGOEL0o2wZWntFXAVcZY4YDmcB1InKJhcdTvhGUeR2T3pXoiFC9S9a9gM1r56hwJmQk8s7mw+1q2GlvsqzQG6cK18sw18NYdTzlG8Ga1/DQEK4cmMCynYXU1gV8uD4X6Hm9JTuF0pNn9IJ6K1naRi8iDhHZDBQBS40xay7ynvtFZL2IrC8uLrYyHOUlwZrXiRmJHDt5hk37v/J3KJYrKqvktrmfU1Re6fE2gZzXr/WNJyFa+9S3lqWF3hhTa4zJBFKA0SIy5CLveckYk22Mye7WTYclDQbBmtcrB3QjzNE+BjmbszyHdQWlzFmW4/E2gZzXUEcIN47swUe7iygu1z71LeWTXjfGmOPASuA6XxxP+Uaw5TU6MoxLendlyY5CjAmYVgmvGvD0h6Q99T6vr9mPMc65V9Oeep8BT3/o8T4CNa+3ZqVQW2d4Z/Mhf4cSdKzsddNNRDq7nncArgF2WXU85RvBnteJGYnkl5wkr7ii+TcHoXnfHkXXjuFnX0eGhXg092ow5LVvQjSZPTuzYMNB235QW8XKM/ok4CMR2QKsw9nm956Fx1O+EdR5vebsIGf2ar6pqKrh2fd3MOPltZRXViNARGgIVTV1ns69GhR5vSUrhV1Hy9mu49S3iGVTCRpjtgAjrNq/8o9gz2tSbAeGpcSydEch37uyr7/DaTNjDO9+eZhffbCTovIqvjGqJ0dPVNKjSxR3jO7F/LX7Kfbggmyw5HXqsGR+8d4OFmw4yJAesf4OJ2jonLGq3ZkwKJFZy/ZQVFZJQkyzZ7oBa09hOf/9zja+2FvK0B6x/OWbWYzo1eW898ycfsH11KAWGxXGxIxEFm0+xI8nDyQi1OHvkIKCDoGg2p2Jg7tjDCzbGZx9siuqavjVBzuZ/Nxqdh4pZ+b0ISx6aOwFRd6ubs3uyfFT1awI0vz5g57Rq3anf2InesVFsXTHUe4Y08vf4XjMGMPiLUd49v0dFJY5m2mevG4gcQ0uvrYHl/eNJzHG2ad+0tAkf4cTFLTQq3ZHRJiQkchrX+yjoqqGThGB/2eQU1jOf7+znc/3HmNIjxj+/M0sRraTM/jGHCHCTSNTeOnjvRSVV3pyobnd06Yb1S5NyEjkTE0dH+8JjLt23alvppn03Gp2HClj5vQhvPPQ5e22yNe7pb5P/SYdp94TWuhVu5Sd2oUuUWEBd5fs2aELyip598vDXP2Hlbz08V5uHpnCisfH8c1LUnGEiL/D9Ls+3Toxsldn3txwQPvUe0ALvWqXQh0hXDUwkWU7C7n1L5+1aEwYK81ZnsO6/FKmPv8JP3hjE/GdIlj4vcv47S3D6Nopwt/hBZRbsnqyp7CCrYd0nPrmaKFX7daEjETKK2tYX/BVi8aEscJ5QxcAha7xXHKLKtp9M407U4YlERGq49R7IvCvQillgQFPf0iVa2xzg3NMmNfX7CciNITdMyf5LI7i8ire/fIwqV2j2FN4bliGyNAQrh3SnZ9OGeSzWIJNbIcwrh3cnXc2H+YnkwcRGaZ96t3RM3rVLq1+cjzTMpNxyLn27q4dw3lwXB8KSk5aeuzK6lre33KEe+at45JfL+eX7+0gItRBVmoXRFxDF9R6PHRBu3ZrdgonTlezXPvUN0nP6FW7lBATSXREKHUYwhxCda2hts4we3kOs5fn0DehE9cMSuSaQQmM6NWlzRdAjTFs2PcVb208xHtbDlNeWUNiTAT3fi2dm0akMKB7NA+8tp47x6S2aOiC9u6yPvEkxUayYMMBpgzTPvXuaKFX7VZJRdUFhfXpKRks31nIsp1F/O/qvfxlVR5xHcO5amAC1wxK5Gv94unYgn73+4+d4u1Nh1i46SD7jp2iQ5iD64Z056aRPbisT/x5HyBzZ2SffW63oQus4uxT34M/r8wL+iEtrKSFXrVb7grr3WPTuXtsOmWV1azaXcyynYUs2X6UBRsOEh4awtg+XbkmI5GrBybSPdZZWIrKKnn4jU28cMcIIsMcfLDlCAs3HmJtQSkAl/buysPj+zJpaFJQ3KAVTG4emcKLH+WxcNMhvjuuj7/DCUj6G6eUGzGRYUwdnszU4clU19axrqCUZTuKWLrzKB+9XcxP2cbQHrFcMyiRXUfLWJdfyq1/+ZyjJyqpqqmjd3xHfnjtAG7ITCalS5S//zm21btbJ7JTu7Bgw0EeuKI3InqfQWNa6JXyQJgjhMv6xHNZn3j+6/pB5BRVsHRHIb//z+7z+nHvO3bK9X5h+ePjtOj4yC1ZKTy1cCtfHjxBZs/O/g4n4GivG6VaSETonxjNQ+P7suYnV3Pt4ETCHM6CXj+j06dPXaVF3ocmD0siMiyEBRsO+DuUgKSFXqk2SIiJJL5TBDV1pqUzOikviokM47rB3Xl382Eqq2v9HU7A0UKvVBvV9955+3tjuXNMKsUVVf4OqV26NbsnZZU1ATd+USDQNnql2ki7RQaGS3t3JTk2kgUbDjJ1eLK/wwkoekavlLKFkBDh5qwUVucUc/SEPW82Ozu6aQtvptNCr5SyjZtHplBnYOEmew509tzyHNYVlLZ4ED5tulFK2UZafEdGp8WxYMNBHhzXJ+h7PtXWGXYeKWP6i59SU3du3P2Gg/B5Qgu9UspWbslK4cm3tjBlzifM+86ooOoBVVNbx/bDZazJP8aavaWsLSilvLIGgKhwB1XVtdQaZzfeawc7RzdNfLb5/WqhV0rZyuRhSfx44RZ2HCljzrIcZt441N8hnTdERsMPnuraOrYcPHG2sG/Y9xUVVc7C3ju+I9cPS2JMelfG9I7jhRW5zF+7v1XdeLXQK6Vso+E8A3CuiSM8NIQ9PpxnoLE5rrb1Py7dw00jU1iz9xhr8p2F/dQZZ7//vgmdmD4i2VnY0+MuGKDtYoPweUoLvVLKNlY/OZ6ZH+xkyfajVFbXITgnlqmuqWPGy2uYntmDa4d099nAco0/eN5Ye4A31jrv3h3YPZpbs1IY07sro9PjiG9mqsi2dOPVQq+Uso36eQaqauqICA3hTG0dU4cmkdq1I4s2H+LxN7/kp4u2MiGjO9Mzk7mifzfCHN7rfGiMIa/4JJ/mlvBJbgmhIULD2+ccIUJWameenT6UfonRXjtuc7TQK6Vs5WJNHE9cO4DHJ/Znw76vWLT5EO9vOcLiLw/TJSqMKcOSuHFED0b26tKqXjpFZZV8mlfCJznH+DS3hKNlziaVXnFRTMvswYHSU3yaV0K4w/nB0z8h2qdFHrTQK6Vsxl0Th4iQnRZHdloc/339YD7eU8yizYd4c/1BXv9iPz3jOnDD8B5MH5FM3wRnIb7YRdSKqhrW7D3GJ7klfJpbcnau3y5RYVzWN57L+8Yztk88vbo6h6YOhJnDtNArpdqd8NAQrslI5JqMRCqqavjPtqMs2nyIP63M5YWPchnSI4bpmT3YcaSMdQWlPP32NjKSY/g0t4RN+4+fHcRudHocN41M4fK+8WQkxRBykSknA2GIDC30Sql2rVNEKDdnpXBzVgpFZZUs3nKEme/tYNuhsrPvWbKjkCU7ChHgwSv7cHnfeEamdiEyzOG/wFtAC71SSrkkxERyz+XpTB2WxFMLt/LxnmJq6pwTyE/ISOSZaYOD6gasejrWjVJKNZIQE0lSbCS1xtlEU1NniIsKD8oiD3pGr5RSF9WWG5QCjRZ6pZS6iEC4iOotljXdiEhPEflIRHaKyHYRecSqYynf0bzak+bV3qw8o68BHjfGbBSRaGCDiCw1xuyw8JjKeppXe9K82phlZ/TGmCPGmI2u5+XATqCHVcdTvqF5tSfNq735pI1eRNKAEcCai6y7H7jf9bJCRHY3WB0PlFgdn5fZIeZUTzbSvAY8zWvz7BBzs3kVY0xz72kTEekErAKeNcYsbOG2640x2c2/M3C0l5g1r4FP89q89hKzpf3oRSQMeAv4R0t/aVTg0rzak+bVvqzsdSPAy8BOY8wsq46jfEvzak+aV3uz8ox+LDADuEpENrsek1u4j5csiMtqdo9Z8xo8NK/NaxcxW95Gr5RSyr90rBullLI5LfRKKWVzAVvoReQ6EdktIrki8pS/42mOiBSIyFZX2+Z6f8dzMSLyNxEpEpFtDZbFichSEclx/exicQxBlVfQ3Hp4fM2rBbyV14As9CLiAF4EJgEZwO0ikuHfqDwy3hiTGcD9cucB1zVa9hSw3BjTD1juem2JIM4raG7d0rxaah5eyGtAFnpgNJBrjNlrjDkD/BO4wc8xBT1jzMdAaaPFNwCvup6/Cky3MATNq0X8nFvNq0W8lddALfQ9gAMNXh8k8MfdMMASEdnguk08WCQaY46Ac7wTIMHCYwVjXkFz2xzNq2+1OK+BOh79hTPsOpMSyMYaYw6LSAKwVER2uT6N1TnBmFfQ3DZH8xrgAvWM/iDQs8HrFOCwn2LxiDHmsOtnEfA2zq+zwaBQRJIAXD+LLDxW0OUVNLce0Lz6VovzGqiFfh3QT0TSRSQc+Abwrp9jcktEOrrG8EZEOgITgW1NbxUw3gXucj2/C3jHwmMFVV5Bc+shzatvtTyvxpiAfACTgT1AHvBTf8fTTKy9gS9dj+2BGi/wBnAEqMZ5FnYP0BXnlfsc1884zavmVvMaGA9v5VWHQFBKKZsL1KYbpZRSXqKFXimlbE4LvVJK2ZwWeqWUsjkt9EopZXNa6JVSyua00PuZiDwjIk/4Ow7lXZpX+wrG3Gqh9yMRadNYQ23dXllD82pfwZpbWxV6EUkTkZ0i8lcR2S4iS0Skg4isFJFs13viRaTA9fxuEVkkIotFJF9EHhaRx0Rkk4h8ISJxbo6TICIbXM+Hi4gRkV6u13kiEiUiqSKyXES2uH7Wr58nIrNE5CPgt432e5+IfOiKuY+I/Ns1st5qERl4se1FZJycm8x5U/1t3XaiebVnXkFz67Pc+vsWXy/fLpwG1ACZrtf/Ar4JrASyXcvigQLX87uBXCAa6AacAL7rWvdH4NEmjrUdiAEexjnWx51AKvC5a/1i4C7X8+8Ai1zP5wHvAQ7X62eAJ1z7eReIcC1fDvRzPR8DrHCz/WKco/ABdAJC/Z0HzavmVXMbWLm141fEfGPMZtfzDTh/kZrykTGmHCgXkRM4kwCwFRjWxHafAWOBK4Bf4ZwFRoDVrvWXAje5nr8G/E+Dbd80xtQ2eD0D5zgW040x1SLSCbgMeFPk7AiwEW62/xSYJSL/ABYaYw428+8NVppX+9LcWsxWTTcuVQ2e1+Icc7+Gc//WyCbeX9fgdR1Nj9e/GvgazjOCd4DhwOWAu/GsGw4qdLLRum04f7lTXK9DgOPGOcVZ/WPQxbY3xvwGuBfoAHxR/3XRhjSv9qW5tZgdC/3FFABZrue3eGmfH+P8ipljjKnDOd3XZJyf1uA8e/iG6/mdwCdN7GsT8ADwrogkG2PKgHwRuRVAnIZfbEMR6WOM2WqM+S2wHrBzQWisAM2rXRWgufWa9lLofw88KCKf4WzvazNjTIHraf3ZwCc4P9G/cr3+AfBtEdmC82veI83s7xOc7X7vi0g8zl+0e0SkfhhVd3NwPioi21zvOw182Mp/UjDSvNqX5taLdJhipZSyufZyRq+UUu2WHXvdeJWIvIjzSn1DzxljXvFHPMo7NK/2pbm9kDbdKKWUzWnTjVJK2ZwWeqWUsjkt9EopZXNa6JVSyub+P9XC/XowAS9cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_MNIST_tensor = datasets.MNIST('./dataset', train=True, download=False, transform= transforms.ToTensor())\n",
    "def fun_timetest(data_loader):\n",
    "    start = time.time()\n",
    "    count=0\n",
    "    for data, target in data_loader:\n",
    "        count+=1\n",
    "    timeimplement = time.time()-start\n",
    "#     print(\"total iteration: {}, a forloop time for whole dataset within CPU: {}s\".format(count, timeimplement) )\n",
    "    return timeimplement\n",
    "\n",
    "###\n",
    "if __name__ == \"__main__\":\n",
    "    for i_subplot, batch_size in enumerate([2,10,100]):\n",
    "        record = []\n",
    "        print(\"batch_size:{}\".format(batch_size))\n",
    "        for i in range(0,12,2):\n",
    "            mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=batch_size, shuffle=True, num_workers=i)\n",
    "    #         print(\"num_workers: {}\".format(i))\n",
    "            timeimplement= fun_timetest(mnistdata_loader)\n",
    "            record.append([i,timeimplement])\n",
    "        record = np.array(record)\n",
    "        plt.subplot(1,3,i_subplot+1)\n",
    "        plt.plot(record[:,0],record[:,1],'*-')\n",
    "        plt.ylim([2,7])\n",
    "        plt.xlabel('num_workers')\n",
    "        plt.ylabel('implement time (s)')\n",
    "        plt.title('batch size:{}'.format(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">num_workers 這個數字不是越高越好，一般建議設定為4~6。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "**<font color = blue size=6 >II. 當dataset是私有資料庫的寫法</font>**\n",
    "\n",
    "我們剛剛介紹了，pytorch的dataloder使用方式，基本上自有的資料庫在dataloader用法完全一樣。\n",
    "\n",
    "**<font color = black size=4>唯一不同的部分在於dataset的宣告。</font>**\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"<br>\n",
    "**<font color = green size=4>dataset_MNIST_tensor = datasets.MNIST('./dataset', train=True, download=False, transform=transform)</font>**\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"<br>\n",
    "\n",
    "<font color = black size=4> 此部分就是要介紹如何在pytorch自定義dataset，也就是「**dataset_MNIST_tensor = datasets.MNIST('./dataset')**」這行怎麼出來的</font><br>\n",
    "\n",
    "<font color = black size=4>**這邊我們用前面私有資料庫介紹的Car Brands Images來說明。**</font><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total data:4597\n",
      "torch.Size([10, 3, 224, 224])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import torchvision.transforms.functional as FT\n",
    "from torchvision import transforms\n",
    "\n",
    "import json\n",
    "__author__ = \"Chih-Sheng(Tommy) Huang\"\n",
    "\n",
    "mytransform=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "class MyDataset_CarBrandsImages(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Class to load the dataset\n",
    "    '''\n",
    "    def __init__(self,transforms):\n",
    "        \n",
    "        with open('./dataset/kaggle/CarBrandsImages/carbrand.json') as jsonfile:\n",
    "            data_load = json.load(jsonfile)\n",
    "        self.imList = data_load['imagepaths']\n",
    "        self.labelList = data_load['labels']\n",
    "        self.transforms=transforms\n",
    "        print('number of total data:{}'.format(len(self.imList)))\n",
    "    def __len__(self):\n",
    "        return len(self.imList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        :param idx: Index of the image file\n",
    "        :return: returns the image and corresponding label file.\n",
    "        '''\n",
    "        image_name = self.imList[idx]\n",
    "        label = self.labelList[idx]\n",
    "        \n",
    "        # read image with PIL module\n",
    "        image = Image.open(image_name, mode='r')\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # Convert PIL label image to torch.Tensor\n",
    "        image = self.transforms(image)\n",
    "        label = torch.tensor(label)\n",
    "        return image, label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mydataset = MyDataset_CarBrandsImages(transforms=mytransform)\n",
    "    mydata_loader = torch.utils.data.DataLoader(mydataset, batch_size=10, num_workers=0)\n",
    "    for data, target in mydata_loader:\n",
    "        print(data.size())\n",
    "        print(target.size())\n",
    "        break    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = blue size=4> workers在私有資料集測試 </font>**<br>\n",
    "\n",
    ">**<font color = red size=3>Windows系統不能處理num_workers>0</font>**<br>\n",
    "\n",
    "**我們這邊試著將worker打開做平行處理**<br>\n",
    "**worker打開後會發生其他問題**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total data:4597\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-82bb29b7d010>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmydataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyDataset_CarBrandsImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmytransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmydata_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmydata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    717\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    mydataset = MyDataset_CarBrandsImages(transforms=mytransform)\n",
    "    mydata_loader = torch.utils.data.DataLoader(mydataset, batch_size=100, num_workers=3)\n",
    "    for data, target in mydata_loader:\n",
    "        print(data.size())\n",
    "        print(target.size())\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Linux執行還是會發生下面這個error<br>\n",
    "**「RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 1 and 0 in dimension 1 at C:\\w\\1\\s\\tmp_conda_3.7_100118\\conda\\conda-bld\\pytorch_1579082551706\\work\\aten\\src\\TH/generic/THTensor.cpp:612」**\n",
    "reference: https://discuss.pytorch.org/t/runtimeerror-invalid-argument-0-sizes-of-tensors-must-match-except-in-dimension-0-pls-help/40852\n",
    "\n",
    "**<font color = red size=3> 原因在於 整個database資料數和batch size的關係</font>**<br>\n",
    ">**<font color = black size=3>整個database有4597筆資料，batch size不論是設為2或是10都是除不盡的，也就是最後一個iteration資料的shape會和前面的都不一樣，這個時候系統就會報錯誤。<br>\n",
    "解決方法: 在dataset的class宣告要多加一個collate_fn。**</font>\n",
    "\n",
    "然後我們要定義一個collate_fn用的function，可以一起定義在mydataset裡面，也可以額外定義function，通常是建議在mydataset定義會比較好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total data:4597\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([97])\n"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    data, target = list(), list()\n",
    "    for b in batch:\n",
    "        data.append(b[0])\n",
    "        target.append(b[1])\n",
    "    data = torch.stack(data,dim=0)\n",
    "    target = torch.stack(target,dim=0)\n",
    "    return data, target\n",
    "mydataset = MyDataset_CarBrandsImages(transforms=mytransform)\n",
    "mydata_loader = torch.utils.data.DataLoader(mydataset, batch_size=100, num_workers=0, collate_fn = my_collate)\n",
    "for data, target in mydata_loader:\n",
    "    print(target.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **這邊我們測試看看如果需要讀圖檔下，開不開workers差多少，請看另一份檔案，或是在Linux下執行**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mydataset = MyDataset_CarBrandsImages(transforms=mytransform)\n",
    "\n",
    "def fun_timetest(data_loader):\n",
    "    start = time.time()\n",
    "    count=0\n",
    "    for data, target in data_loader:\n",
    "        count+=1\n",
    "    timeimplement = time.time()-start\n",
    "    print(\"total iteration: {}, a forloop time for whole dataset within CPU: {}s\".format(count, timeimplement) )\n",
    "    return timeimplement\n",
    "\n",
    "for i in [0, 2, 4, 8]:\n",
    "    mydata_loader = torch.utils.data.DataLoader(mydataset, batch_size=24, num_workers=i)\n",
    "    print(\"\\n num_workers: {}\".format(i))\n",
    "    timeimplement = fun_timetest(mydata_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------\n",
    "**<font color = blue size=6 >III. 如何將資料丟到CUDA。</font>**\n",
    "\n",
    "\n",
    "在torch的tensor下直接.to(device)即可，但device需要先宣告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "tensor([5, 0])\n",
      "tensor([5, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "transform = transforms.ToTensor()\n",
    "dataset_MNIST_tensor = datasets.MNIST('./dataset', train=True, download=False, transform=transform)\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=2)\n",
    "\n",
    "\n",
    "use_cuda = 1\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "for data, target in mnistdata_loader:\n",
    "    print(target)\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我們針對CPU mode的tensor和CUDA mode的tensor做操作看看\n",
    "\n",
    "### 1. CPU Tensor 相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "use_cuda = 1\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "one = torch.Tensor([1])\n",
    "for data, target in mnistdata_loader:\n",
    "    print(data+one)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CUDA Tensor 加 CPU Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cuda:0 but got device cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f10d0fe6dc87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmnistdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cuda:0 but got device cpu"
     ]
    }
   ],
   "source": [
    "for data, target in mnistdata_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    print(data+one)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CUDA Tensor 加 CUDA Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "one = torch.Tensor([1])\n",
    "one = one.to(device)\n",
    "for data, target in mnistdata_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    print(target+one)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 測試CPU和CUDA之間資料搬移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When batch size = 10\n",
      "a forloop time for whole dataset within CPU: 4.247750759124756s\n",
      "a forloop time for whole dataset with CPU to CUDA: 5.4835333824157715s\n",
      "\n",
      "When batch size = 2\n",
      "a forloop time for whole dataset within CPU: 4.938941717147827s\n",
      "a forloop time for whole dataset with CPU to CUDA: 8.394227981567383s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def test_time(data_loader):\n",
    "    start = time.time()\n",
    "    count=0\n",
    "    for data, target in data_loader:\n",
    "        count+=1\n",
    "    print(\"a forloop time for whole dataset within CPU: {}s\".format(time.time()-start))\n",
    "\n",
    "    start = time.time()\n",
    "    count=0\n",
    "    for data, target in data_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        count+=1\n",
    "    print(\"a forloop time for whole dataset with CPU to CUDA: {}s\".format(time.time()-start))\n",
    "    \n",
    "print(\"When batch size = 10\")\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=10, shuffle=False)\n",
    "test_time(mnistdata_loader)\n",
    "\n",
    "print(\"\\nWhen batch size = 2\")\n",
    "mnistdata_loader = torch.utils.data.DataLoader(dataset_MNIST_tensor, batch_size=2, shuffle=False)\n",
    "test_time(mnistdata_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</font>**<font color = black size=4 >Note: </font>**<br>\n",
    "\n",
    "**<font color = black size=3 >1:資料跑來跑去一定花費data bandwidth，導致時間會變慢，所以在pytorch撰寫過程中要盡量避免資料在CPU和GPU之間跑來跑去。</font>**<br>\n",
    "\n",
    "**<font color = black size=3 >2: 容易造成CPU的tensor和CUDA的tensor進行運算的error，在進行運算要注意是在CPU還是CUDA。</font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
