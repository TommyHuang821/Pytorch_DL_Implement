{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worst-discovery",
   "metadata": {},
   "source": [
    "# pytorch - 手刻ResNet18\n",
    "Residual Network :https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optical-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class RESNET18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(RESNET18, self).__init__()\n",
    "        # _resnet('resnet18', BasicBlock, [2, 2, 2, 2])\n",
    "        channel_ration = 0.1\n",
    "\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        outch =  int(64 * channel_ration)\n",
    "        self.conv1 = nn.Conv2d(3, outch, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(outch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        '''\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        '''\n",
    "\n",
    "        # layer 1\n",
    "        outch =  int(64 * channel_ration)\n",
    "        self.l1_p1_conv1 = conv3x3(outch, outch, 1)\n",
    "        self.l1_p1_bn1 = norm_layer(outch)\n",
    "        self.l1_relu = nn.ReLU(inplace=True)\n",
    "        self.l1_p1_conv2 = conv3x3(outch, outch)\n",
    "        self.l1_p1_bn2 = norm_layer(outch)\n",
    "        \n",
    "        self.l1_p2_conv1 = conv3x3(outch, outch, 1)\n",
    "        self.l1_p2_bn1 = norm_layer(outch)\n",
    "        self.l1_p2_relu = nn.ReLU(inplace=True)\n",
    "        self.l1_p2_conv2 = conv3x3(outch, outch)\n",
    "        self.l1_p2_bn2 = norm_layer(outch)\n",
    "        \n",
    "         # layer 2\n",
    "        inch =  int(64 * channel_ration)\n",
    "        outch =  int(128 * channel_ration)\n",
    "        self.downsample2 = nn.Sequential(\n",
    "                conv1x1(inch, outch, 2),\n",
    "                norm_layer(outch),\n",
    "            )\n",
    "        self.l2_p1_conv1 = conv3x3(inch, outch, 2)\n",
    "        self.l2_p1_bn1 = norm_layer(outch)\n",
    "        self.l2_relu = nn.ReLU(inplace=True)\n",
    "        self.l2_p1_conv2 = conv3x3(outch, outch)\n",
    "        self.l2_p1_bn2 = norm_layer(outch)\n",
    "        \n",
    "        self.l2_p2_conv1 = conv3x3(outch, outch, 1)\n",
    "        self.l2_p2_bn1 = norm_layer(outch)\n",
    "        self.l2_p2_relu = nn.ReLU(inplace=True)\n",
    "        self.l2_p2_conv2 = conv3x3(outch, outch)\n",
    "        self.l2_p2_bn2 = norm_layer(outch)\n",
    "        \n",
    "        # layer 3\n",
    "        inch =  int(128 * channel_ration)\n",
    "        outch =  int(256 * channel_ration)\n",
    "        self.downsample3 = nn.Sequential(\n",
    "                conv1x1(inch, outch, 2),\n",
    "                norm_layer(outch),\n",
    "            )    \n",
    "        self.l3_p1_conv1 = conv3x3(inch, outch, 2)\n",
    "        self.l3_p1_bn1 = norm_layer(outch)\n",
    "        self.l3_relu = nn.ReLU(inplace=True)\n",
    "        self.l3_p1_conv2 = conv3x3(outch, outch)\n",
    "        self.l3_p1_bn2 = norm_layer(outch)\n",
    "        \n",
    "        self.l3_p2_conv1 = conv3x3(outch, outch, 1)\n",
    "        self.l3_p2_bn1 = norm_layer(outch)\n",
    "        self.l3_p2_relu = nn.ReLU(inplace=True)\n",
    "        self.l3_p2_conv2 = conv3x3(outch, outch)\n",
    "        self.l3_p2_bn2 = norm_layer(outch)\n",
    "        \n",
    "        # layer 4\n",
    "        inch =  int(256 * channel_ration)\n",
    "        outch =  int(512 * channel_ration)\n",
    "        self.downsample4 = nn.Sequential(\n",
    "                conv1x1(inch, outch, 2),\n",
    "                norm_layer(outch),\n",
    "            )     \n",
    "        self.l4_p1_conv1 = conv3x3(inch, outch, 2)\n",
    "        self.l4_p1_bn1 = norm_layer(outch)\n",
    "        self.l4_relu = nn.ReLU(inplace=True)\n",
    "        self.l4_p1_conv2 = conv3x3(outch, outch)\n",
    "        self.l4_p1_bn2 = norm_layer(outch)\n",
    "        \n",
    "        self.l4_p2_conv1 = conv3x3(outch, outch, 1)\n",
    "        self.l4_p2_bn1 = norm_layer(outch)\n",
    "        self.l4_p2_relu = nn.ReLU(inplace=True)\n",
    "        self.l4_p2_conv2 = conv3x3(outch, outch)\n",
    "        self.l4_p2_bn2 = norm_layer(outch)\n",
    "   \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(outch , num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):    \n",
    "        # 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "                \n",
    "        # 2,3\n",
    "        identity11 = x\n",
    "        x = self.l1_p1_conv1(x)\n",
    "        x = self.l1_p1_bn1(x)\n",
    "        x = self.l1_relu(x)\n",
    "        x = self.l1_p1_conv2(x)\n",
    "        x = self.l1_p1_bn2(x)\n",
    "        x += identity11\n",
    "        x = self.l1_relu(x)\n",
    "        # 4,5\n",
    "        identity12 = x\n",
    "        x = self.l1_p2_conv1(x)\n",
    "        x = self.l1_p2_bn1(x)\n",
    "        x = self.l1_p2_relu(x)\n",
    "        x = self.l1_p2_conv2(x)\n",
    "        x = self.l1_p2_bn2(x)\n",
    "        x += identity12\n",
    "        x = self.l1_p2_relu(x)\n",
    "        \n",
    "        \n",
    "        # 6,7\n",
    "        identity21 = self.downsample2(x)\n",
    "        x = self.l2_p1_conv1(x)\n",
    "        x = self.l2_p1_bn1(x)\n",
    "        x = self.l2_relu(x)\n",
    "        x = self.l2_p1_conv2(x)\n",
    "        x = self.l2_p1_bn2(x)\n",
    "        x += identity21\n",
    "        x = self.l2_relu(x)\n",
    "        # 8,9\n",
    "        identity22 = x\n",
    "        x = self.l2_p2_conv1(x)\n",
    "        x = self.l2_p2_bn1(x)\n",
    "        x = self.l2_p2_relu(x)\n",
    "        x = self.l2_p2_conv2(x)\n",
    "        x = self.l2_p2_bn2(x)\n",
    "        x += identity22\n",
    "        x = self.l2_p2_relu(x)\n",
    "        \n",
    "        \n",
    "        # 10,11\n",
    "        identity31 = self.downsample3(x)\n",
    "        x = self.l3_p1_conv1(x)\n",
    "        x = self.l3_p1_bn1(x)\n",
    "        x = self.l3_relu(x)\n",
    "        x = self.l3_p1_conv2(x)\n",
    "        x = self.l3_p1_bn2(x)\n",
    "        x += identity31\n",
    "        x = self.l3_relu(x)\n",
    "        # 12,13\n",
    "        identity32 = x\n",
    "        x = self.l3_p2_conv1(x)\n",
    "        x = self.l3_p2_bn1(x)\n",
    "        x = self.l3_p2_relu(x)\n",
    "        x = self.l3_p2_conv2(x)\n",
    "        x = self.l3_p2_bn2(x)\n",
    "        x += identity32\n",
    "        x = self.l3_p2_relu(x)\n",
    "        \n",
    "                # 14,15\n",
    "        identity41 = self.downsample4(x)\n",
    "        x = self.l4_p1_conv1(x)\n",
    "        x = self.l4_p1_bn1(x)\n",
    "        x = self.l4_relu(x)\n",
    "        x = self.l4_p1_conv2(x)\n",
    "        x = self.l4_p1_bn2(x)\n",
    "        x += identity41\n",
    "        x = self.l4_relu(x)\n",
    "        \n",
    "        # 16,17\n",
    "        identity42 = x\n",
    "        x = self.l4_p2_conv1(x)\n",
    "        x = self.l4_p2_bn1(x)\n",
    "        x = self.l4_p2_relu(x)\n",
    "        x = self.l4_p2_conv2(x)\n",
    "        x = self.l4_p2_bn2(x)\n",
    "        x += identity42\n",
    "        x = self.l4_p2_relu(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "individual-sheet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESNET18(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (l1_p1_conv1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l1_p1_bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1_relu): ReLU(inplace=True)\n",
      "  (l1_p1_conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l1_p1_bn2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1_p2_conv1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l1_p2_bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1_p2_relu): ReLU(inplace=True)\n",
      "  (l1_p2_conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l1_p2_bn2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample2): Sequential(\n",
      "    (0): Conv2d(6, 12, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (l2_p1_conv1): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (l2_p1_bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l2_relu): ReLU(inplace=True)\n",
      "  (l2_p1_conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l2_p1_bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l2_p2_conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l2_p2_bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l2_p2_relu): ReLU(inplace=True)\n",
      "  (l2_p2_conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l2_p2_bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample3): Sequential(\n",
      "    (0): Conv2d(12, 25, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (l3_p1_conv1): Conv2d(12, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (l3_p1_bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l3_relu): ReLU(inplace=True)\n",
      "  (l3_p1_conv2): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l3_p1_bn2): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l3_p2_conv1): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l3_p2_bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l3_p2_relu): ReLU(inplace=True)\n",
      "  (l3_p2_conv2): Conv2d(25, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l3_p2_bn2): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample4): Sequential(\n",
      "    (0): Conv2d(25, 51, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (l4_p1_conv1): Conv2d(25, 51, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (l4_p1_bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l4_relu): ReLU(inplace=True)\n",
      "  (l4_p1_conv2): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l4_p1_bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l4_p2_conv1): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l4_p2_bn1): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l4_p2_relu): ReLU(inplace=True)\n",
      "  (l4_p2_conv2): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (l4_p2_bn2): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=51, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "restnet18_ = RESNET18(num_classes=10)\n",
    "print(restnet18_)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "out = restnet18_(dummy_input)\n",
    "torch.onnx.export(restnet18_, dummy_input, \"restnet18_.onnx\", opset_version=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-conversion",
   "metadata": {},
   "source": [
    "# Network visualization\n",
    "Netron: https://netron.app/\n",
    "<br>\n",
    "https://github.com/lutzroeder/netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "planned-median",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "use_cuda = 1\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available() & use_cuda) else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 步驟1. data loader處理 \n",
    "mytransform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "n_batch=256\n",
    "total_epoch = 150\n",
    "milestones=[30,60,90,120]\n",
    "\n",
    "model = RESNET18(num_classes=10).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "dataset_train = datasets.CIFAR10(root='./dataset', train=True,  download=False, transform=mytransform)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=n_batch, num_workers=0, shuffle=True)\n",
    "testset = datasets.CIFAR10(root='./dataset', train=False, download=False, transform=mytransform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=n_batch, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "married-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalmodel(model, testloader, loss):\n",
    "    model.eval()\n",
    "    test_loss_cnn = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(testloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output_cnn = model(data)\n",
    "            loss_cnn = loss(output_cnn,target)  \n",
    "            test_loss_cnn += loss_cnn\n",
    "            _, predicted = torch.max(output_cnn.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "\n",
    "    test_loss_cnn /= len(testloader.dataset)\n",
    "    acc = 100 * correct / total\n",
    "    return test_loss_cnn, acc\n",
    "\n",
    "def train(model, optimizer,dataloader_train, testloader, loss, total_epoch, scheduler):\n",
    "    # 步驟5. CNN模型開始訓練\n",
    "    log_loss_train=[]\n",
    "    log_loss_test=[]\n",
    "    \n",
    "    for epoch in range(total_epoch):\n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss_cnn = 0\n",
    "        for batch_idx, (data, target) in enumerate(dataloader_train):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output_cnn = model(data)\n",
    "            loss_cnn = loss(output_cnn,target)  \n",
    "            train_loss_cnn += loss_cnn\n",
    "            loss_cnn.backward()\n",
    "            optimizer.step()\n",
    "        train_loss_cnn /= len(dataloader_train.dataset)\n",
    "        scheduler.step()\n",
    "    \n",
    "        if epoch % 10 == 0:\n",
    "            train_loss, train_acc= evalmodel(model, dataloader_train, loss)\n",
    "            test_loss, test_acc= evalmodel(model, testloader, loss)\n",
    "            \n",
    "            log_loss_train.append(train_loss)\n",
    "            log_loss_test.append(test_loss)\n",
    "            print('learning rate:{}'.format(scheduler.get_last_lr()[0]))\n",
    "            print('CNN[epoch: [{}/{}], Average loss (Train):{:.5f}, Average loss (test):{:.5f}, acc(train):{:.4f}, acc(test):{:.4f}'.format(\n",
    "                epoch+1, total_epoch, train_loss, test_loss, train_acc, test_acc))\n",
    "                      \n",
    "    print('CNN[epoch: [{}/{}], Average loss (Train):{:.5f}, Average loss (test):{:.5f}, acc(train):{:.4f}, acc(test):{:.4f}'.format(\n",
    "                epoch+1, total_epoch, train_loss, test_loss, train_acc, test_acc))\n",
    "    print('training done.')\n",
    "    return log_loss_train, log_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accompanied-corps",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Training....\n",
      "learning rate:0.01\n",
      "CNN[epoch: [1/150], Average loss (Train):0.00644, Average loss (test):0.00663, acc(train):38.5560, acc(test):38.1400\n",
      "learning rate:0.01\n",
      "CNN[epoch: [11/150], Average loss (Train):0.00444, Average loss (test):0.00516, acc(train):59.4760, acc(test):53.4200\n",
      "learning rate:0.01\n",
      "CNN[epoch: [21/150], Average loss (Train):0.00380, Average loss (test):0.00495, acc(train):65.2480, acc(test):56.4700\n",
      "learning rate:0.005\n",
      "CNN[epoch: [31/150], Average loss (Train):0.00311, Average loss (test):0.00504, acc(train):71.8820, acc(test):57.5700\n",
      "learning rate:0.005\n",
      "CNN[epoch: [41/150], Average loss (Train):0.00273, Average loss (test):0.00534, acc(train):75.7760, acc(test):56.9600\n",
      "learning rate:0.005\n",
      "CNN[epoch: [51/150], Average loss (Train):0.00266, Average loss (test):0.00574, acc(train):75.8140, acc(test):56.3800\n",
      "learning rate:0.0025\n",
      "CNN[epoch: [61/150], Average loss (Train):0.00206, Average loss (test):0.00591, acc(train):82.0160, acc(test):56.9600\n",
      "learning rate:0.0025\n",
      "CNN[epoch: [71/150], Average loss (Train):0.00189, Average loss (test):0.00644, acc(train):83.6480, acc(test):55.9900\n",
      "learning rate:0.0025\n",
      "CNN[epoch: [81/150], Average loss (Train):0.00180, Average loss (test):0.00678, acc(train):84.1680, acc(test):55.2700\n",
      "learning rate:0.00125\n",
      "CNN[epoch: [91/150], Average loss (Train):0.00146, Average loss (test):0.00700, acc(train):88.0620, acc(test):55.2600\n",
      "learning rate:0.00125\n",
      "CNN[epoch: [101/150], Average loss (Train):0.00131, Average loss (test):0.00749, acc(train):89.3220, acc(test):54.9800\n",
      "learning rate:0.00125\n",
      "CNN[epoch: [111/150], Average loss (Train):0.00126, Average loss (test):0.00776, acc(train):89.7680, acc(test):54.6700\n",
      "learning rate:0.000625\n",
      "CNN[epoch: [121/150], Average loss (Train):0.00108, Average loss (test):0.00795, acc(train):92.0380, acc(test):55.1300\n",
      "learning rate:0.000625\n",
      "CNN[epoch: [131/150], Average loss (Train):0.00102, Average loss (test):0.00831, acc(train):92.5260, acc(test):54.6000\n",
      "learning rate:0.000625\n",
      "CNN[epoch: [141/150], Average loss (Train):0.00099, Average loss (test):0.00849, acc(train):92.6600, acc(test):54.5000\n",
      "CNN[epoch: [150/150], Average loss (Train):0.00099, Average loss (test):0.00849, acc(train):92.6600, acc(test):54.5000\n",
      "training done.\n"
     ]
    }
   ],
   "source": [
    "print('*'*50)\n",
    "print('Training....')\n",
    "loss_log_rain, loss_log_test = train(model, optimizer, dataloader_train, testloader, criterion, total_epoch=total_epoch, scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compressed-facing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0UElEQVR4nO3dd3xVVbbA8d9KJ4UEAqGkAYIUFRApAUQFRQERxIKoYBnnoYM4OKMz4lhGnzPvOTrOUywg9oKi4+iIigKOYKF3pBOQkBBKCCYkgZC23x/7BkJIuZhyblnfz+d+knvO2TfrQLLXOXvvs7cYY1BKKeV/ApwOQCmllDM0ASillJ/SBKCUUn5KE4BSSvkpTQBKKeWnNAEopZSf0gSglFJ+ShOAUlUQkd0icpnTcSjVkDQBKKWUn9IEoJSbRCRURJ4VkUzX61kRCXXtayEin4tIjogcFpHvRSTAte8BEdkrInkisk1ELnX2TJSygpwOQCkv8hCQAvQEDPAp8DDwCHAfkAG0dB2bAhgR6QxMBvoYYzJFpB0Q2LhhK1U1vQNQyn03A/9tjDlojMkCHgcmuPYVA22AZGNMsTHme2Mn2ioFQoFuIhJsjNltjNnpSPRKVaIJQCn3tQXSKrxPc20DeBpIBeaLyC4RmQpgjEkF7gUeAw6KyGwRaYtSHkATgFLuywSSK7xPcm3DGJNnjLnPGNMBuAr4fXlbvzHmPWPMha6yBvhb44atVNU0AShVvWARCSt/Ae8DD4tISxFpATwKvAsgIiNFpKOICHAE2/RTKiKdRWSIq7O4EDjm2qeU4zQBKFW9udgKu/wVBqwCNgA/AmuAv7iO7QR8DeQDS4GXjDGLsO3/TwKHgP1AHPCnRjsDpWoguiCMUkr5J70DUEopP6UJQCml/JQmAKWU8lOaAJRSyk951VQQLVq0MO3atXM6DKWU8iqrV68+ZIxpWXm7VyWAdu3asWrVKqfDUEopryIiaVVt1yYgpZTyU5oAlFLKT2kCUEopP+VVfQBVKS4uJiMjg8LCQqdDaVBhYWEkJCQQHBzsdChKKR/h9QkgIyODqKgo2rVrh52Hy/cYY8jOziYjI4P27ds7HY5Sykd4fRNQYWEhsbGxPlv5A4gIsbGxPn+Xo5RqXF6fAACfrvzL+cM5KqUal08kAKWU8kmHDsHnn8NDD0F6er1/vCaAOsrJyeGll14643IjRowgJyen/gNSSnmn0lL48UeYORNuuw06d4aWLeGqq+Bvf4P16+v9R3p9J7DTyhPApEmTTtleWlpKYGBgteXmzp3b0KEppTxZbi4sXw5LlsDSpbBsGRw5Yve1aAEDBsDtt0P//tC7N0RE1HsImgDqaOrUqezcuZOePXsSHBxMZGQkbdq0Yd26dWzevJmrr76a9PR0CgsLmTJlChMnTgROTmuRn5/P8OHDufDCC1myZAnx8fF8+umnNGnSxOEzU0rVG2Ng+3Zb0ZdX+Js22e0BAXDuuXDTTbayHzAAzjoLGqHfz6cSwOOfbWJz5pF6/cxubZvy56vOqXb/k08+ycaNG1m3bh2LFi3iyiuvZOPGjSeGa77++us0b96cY8eO0adPH6699lpiY2NP+YwdO3bw/vvv88orrzB27Fj+9a9/MX78+Ho9D6VUI8rPh5UrT1b4y5ZBdrbdFxNjK/qxY+3Xvn2haVNHwvSpBOAJ+vbte8pY/WnTpvHJJ58AkJ6ezo4dO05LAO3bt6dnz54AXHDBBezevbuxwlVK1Zft2+Hll2HhQtiwwbbpA3TtCldfffLqvnNne9XvAXwqAdR0pd5YIiq00y1atIivv/6apUuXEh4eziWXXFLlWP7Q0NAT3wcGBnLs2LFGiVUpVUdlZTBvHjz/PHz5JQQHw0UXwZ/+ZCv7fv2gWTOno6yWTyUAJ0RFRZGXl1flvtzcXJo1a0Z4eDhbt25l2bJljRydUqpBHDkCb71lK/4dO6B1a3j8cZg40X7vJTQB1FFsbCwDBw7k3HPPpUmTJrRq1erEvmHDhjFjxgy6d+9O586dSUlJcTBSpVSdbd8OL7wAb74JeXmQkmIr/muvhZAQp6M7Y2KMcToGt/Xu3dtUXhBmy5YtdO3a1aGIGpc/natSHqOsDObPh2nTTjbz3HAD3HOP7cD1AiKy2hjTu/J2vQNQSqmq5OWdbObZvt027Tz2GNx5p1c189TEra5oERkmIttEJFVEplaxX0Rkmmv/BhHpVVtZEekpIstEZJ2IrBIR70ilSinftmMHTJkC8fH2Kr9ZM5g1C9LS4M9/9pnKH9y4AxCRQOBFYCiQAawUkTnGmM0VDhsOdHK9+gHTgX61lH0KeNwY86WIjHC9v6TezkwppdxVVgYLFthmnrlzbTPP2LE2AfTr53R0DcadJqC+QKoxZheAiMwGRgMVE8Bo4G1jOxSWiUiMiLQB2tVQ1gDlTz9EA5l1Px2llDoDeXnw9tu2mWfbNmjVyl7l33kntGnjdHQNzp0EEA9UnIYuA3uVX9sx8bWUvReYJyJ/xzZFDajqh4vIRGAiQFJSkhvhKqVUDUpK7MRq77wDb7xhh3T26QPvvgvXXQcVnsvxde4kgKompKg8dKi6Y2oq+xvgd8aYf4nIWOA14LLTDjZmJjAT7CggN+JVSqmTcnPtVAyLF9vX8uVQUGCbea6/Hn77W59u5qmJOwkgA0is8D6B05trqjsmpIaytwJTXN//E3jVvZA9S05ODu+9995ps4G649lnn2XixImEh4c3QGRK+SFjbGdteWW/eLGdYrl80rXu3e1UywMHwpAhtsnHj7mTAFYCnUSkPbAXGAfcVOmYOcBkVxt/PyDXGLNPRLJqKJsJXAwsAoYAO+p4Lo6objpodzz77LOMHz9eE4BSv1RxsW3OqVjhZ7quMSMj7fw7Y8bYCr9fP8cmXfNUtSYAY0yJiEwG5gGBwOvGmE0icpdr/wxgLjACSAWOArfXVNb10f8FPCciQUAhrnZ+b1NxOuihQ4cSFxfHhx9+yPHjxxkzZgyPP/44BQUFjB07loyMDEpLS3nkkUc4cOAAmZmZDB48mBYtWrBw4UKnT0Upz5eTY2fYLK/sV6yAo0ftvqQkuPhiW9kPHAjnnQc1rMmh3HwQzBgzF1vJV9w2o8L3Brjb3bKu7T8AF5xJsLW6915Yt65eP5KePeHZZ6vdXXE66Pnz5/PRRx+xYsUKjDGMGjWK7777jqysLNq2bcsXX3wB2DmCoqOj+cc//sHChQtp0aJF/caslK/IyoKvvjpZ4ZfPoR8YaP8277jjZIWfkOB0tF5HnwSuR/Pnz2f+/Pmcf/75AOTn57Njxw4GDRrE/fffzwMPPMDIkSMZNGiQw5Eq5cGysuDjj+Gf/7RTK5eV2aab8jn0Bw60UzBERjodqdfzrQRQw5V6YzDG8OCDD3LnnXeetm/16tXMnTuXBx98kMsvv5xHH33UgQiV8lBVVfpnnw0PPgjXXAM9emhzTgPwrQTggIrTQV9xxRU88sgj3HzzzURGRrJ3716Cg4MpKSmhefPmjB8/nsjISN58881TymoTkPJLNVX6Y8faNvxGWBbRn2kCqKOK00EPHz6cm266if79+wMQGRnJu+++S2pqKn/4wx8ICAggODiY6dOnAzBx4kSGDx9OmzZttBNY+YesLPjkE/jwQ1i0yK6apZW+Y3Q6aC/iT+eqfEh1lf7119tX9+5a6TcwnQ5aKdV4yiv98uad0lLo1AmmTtVK34NoAlBK1Q+t9L2OTyQAYwzi479Y3tRUp/xMXh488YQdhVdcrJW+F/H6BBAWFkZ2djaxsbE+mwSMMWRnZxMWFuZ0KEqdZIxdKOWPf4R9++wcO/feq5W+F/H6BJCQkEBGRgZZWVlOh9KgwsLCSNAnHZWnWLvWLpayeLGdSvmTT/x2Rk1v5vUJIDg4mPbt2zsdhlL+ITsbHn4YZs6E2Fh49VW4/XY706byOvq/ppSqXWkpTJ9uh2++8gpMnmwXSr/jDq38vZjX3wEopRrYDz/Y5p516+CSS+zyieee63RUqh5o6lZKVS0zE8aPh0GD4NAh+OAD+OYbrfx9iCYApdSpiorgqaegc2c7pv+hh2DrVjtVg47u8SnaBKSUOumrr2DKFNu+P2oU/OMfcNZZTkelGojeASilYNcuGD0ahg+377/8Ej79VCt/H+dWAhCRYSKyTURSRWRqFftFRKa59m8QkV61lRWRD0Rkneu1W0TW1csZKaXcd/QoPPIIdOtm2/f/9je7iPqwYU5HphpBrU1AIhIIvAgMBTKAlSIyxxizucJhw4FOrlc/YDrQr6ayxpgbKvyMZ4DcejonpVRtjIGPPoL77oP0dLj5Ztvu37at05GpRuTOHUBfINUYs8sYUwTMBkZXOmY08LaxlgExItLGnbJi528YC7xfx3NRStXGGFi9Gi691HbqxsbC99/Du+9q5e+H3OkEjgfSK7zPwF7l13ZMvJtlBwEHjDE73AlYKXWG9u+Hr7+GBQvs18xMaN4cXnoJJk7UpRb9mDsJoKpxX5WnpqzuGHfK3kgNV/8iMhGYCJCUlFR9lEopq6AAvvvOVvgLFsDGjXZ7bCxcdpl9XXONTQLKr7mTADKAxArvE4BMN48JqamsiAQB1wAXVPfDjTEzgZlgVwRzI16l/EtpKaxadfIqf8kSOy1zaKh9iGv8eBg6FHr21Gkb1CncSQArgU4i0h7YC4wDbqp0zBxgsojMxjbx5Bpj9olIVi1lLwO2GmMy6ngeSvkPY2DnzpMV/jffQE6O3Xf++XZK5qFD4cILoUkTJyNVHq7WBGCMKRGRycA8IBB43RizSUTucu2fAcwFRgCpwFHg9prKVvj4cWjnr1K1y86G//znZKW/e7fdnphom3OGDrUduy1bOhqm8i5evyi8Uj7JGNus8/HHtsJfs8Zua9oUBg+2Ff7QoXb1LZ2eQdVCF4VXyhsUFMD779upl9esgaAg6N8fHnvMVvh9+thtStUD/U1SyhNs3gwzZsDbb0Nurp1x88UX7QNa0dFOR6d8lCYApZxSVGSXUpw+Hb79FkJC4Lrr4De/gYEDtWlHNTj/SABr18LSpTBpktORKAVpaXZJxddegwMHoH17ePJJu7RiXJzT0Sk/4h8J4JVX7B/ckCHQpYvT0Sh/VFoK8+bZq/25c+22K6+0V/tXXKHj85Uj/OO37rHHICIC/vAHpyNR/ubgQXt137GjrfBXrICpU+30y3Pm2OmXtfJXDvGP37y4OLuq0eef27HUSjUkY+wEazfdBAkJ8OCDkJwMs2fbmTf/+lf7XimH+c9zAIWFtvknJsbOhqgTYKn6duQIvPOOHc2zcaMds3/rrXDXXXa+faUcUt1zAH5xB5B6MJ9Pt2bbxS7Wr4e33nI6JOVL9uyxlXzbtjB5sh3N88ordtbNadO08lceyy8SwGs//MQD/9pA7sgxkJICDz8M+flOh6W8XWnpyQr+rbfg+uth+XL7BO+vf237nZTyYH6RAManJFFYXMZHa/faRa737YOnn3Y6LOXNNm2yk61NmWK/btkCb7wBffvq+H3lNfwiAZzTNppeSTHMWpaGSUmBG26wCWDvXqdDU97m+HE7quz882HHDtvm/+WX0K6d05Epdcb8IgEAjE9JZtehApbszIb//V97+/7QQ06HpbzJkiW24n/8cdvcs2WLnWtfr/iVl/KbBDDivDY0Cw/mnaVp9snLe++17bZr1jgdmvJ0eXm2c/fCC23f0RdfwKxZOvWy8np+kwDCggMZ2zuRBVsOsD+3EP70J2jRAu67z47bVqoqX3xhO3lfegnuuce2/Y8Y4XRUStULv0kAADf1S6LMGN5fscfOsPj447BokX0iU6mKDh60D3KNHGnH8y9eDM89B1FRTkemVL3xqwSQHBvBxWe3ZPbKPRSXlsHEidC1q50ioqjI6fCUJzDGTsnctSt89JG9SFi71s7Jr5SP8asEADC+XzIHjhzn680H7MIaTz9tR3PMmOF0aMppP/0Ew4bZp3c7d4Z16+DRR+2DXUr5ILcSgIgME5FtIpIqIlOr2C8iMs21f4OI9HKnrIjc49q3SUSeqvvp1G5wlzjiY5rwzrI0u2HECLjsMnul9/PPjRGC8jSlpfB//2cXYVmyBF54AX74QZ/gVT6v1gQgIoHAi8BwoBtwo4hU/ssYDnRyvSYC02srKyKDgdFAd2PMOcDf6+OEahMYINzUL4klO7NJPZhvh/A984yt/P/yl8YIQXmSDRts887vfw+XXGI7ee++W2foVH7Bnd/yvkCqMWaXMaYImI2tuCsaDbxtrGVAjIi0qaXsb4AnjTHHAYwxB+vhfNwytnciwYHCrOWuu4Du3eFXv4Lnn4fU1MYKQzmpsNBOCXLBBbB7t12H9/PPISnJ6ciUajTuJIB4IL3C+wzXNneOqans2cAgEVkuIt+KSJ+qfriITBSRVSKyKisry41wa9cyKpTh57bho9UZHC0qsRufeMK29T7wQL38DOXBvv8eeva00zLfdJN9oGvcOH2gS/kddxJAVX8VlQfOV3dMTWWDgGZACvAH4EOR0/8CjTEzjTG9jTG9W9bjgzfjU5LJKyzhs/WZdkObNrby//hjW0Eo33LwoL3C//Wv4aKL7JQO8+bZhwFjY52OTilHuLMkZAaQWOF9ApDp5jEhNZTNAD42dkGCFSJSBrQA6ucyvxZ92jWjc6so3lmWxtjeiYiIfSjs5Zdte/Dy5doO7K2OHrVrPqxYYV/Ll9t1eMGO/Prd7+wdn87WqfycOzXcSqCTiLQXkRBgHFD5yak5wC2u0UApQK4xZl8tZf8NDAEQkbOxyeJQXU/IXSLC+JQkNu49wvqMXLsxPNzOE7RqlW0TVp6vtBR+/BFefdU+19Gzp31w66KL4P77bQLo1w/+/nd7Z5eTY2eE1cpfqdrvAIwxJSIyGZgHBAKvG2M2ichdrv0zgLnACCAVOArcXlNZ10e/DrwuIhuBIuBW08jLk119fjxPfrmVd5am0TMxxm68+Wb7xOfUqTBmjE0KyjMYY5dULL+qX7HCXukXFNj9MTF2OuZRo+zXPn2gVStHQ1bKk/nPkpDVeOiTH/lodQbLHryUZhGuB36+/dYOCfzLX3TGUCfl5MDKlac25Rw4YPeFhNiZOfv2tVf4ffvahde1I1ep01S3JKQ7fQA+bXxKMrOW7+Gj1Rn810Ud7MaLL7ZX/08+CXfcAa1bOxukPykrg08+sct3rlx5cnvnznDFFbai79sXevTQJ3SVqiO/7+Xs2qYpfdo1Y9byNMrKKtwN/e1vdqz4o486F5w/KSmxUyyfdx5cd529+n/iCViwwD6kt3WrHbFz9922aUcrf6XqzO8TANi7gN3ZR/khtUIfdKdOdg74116znYyqYRQXw+uv28nXyhdXef99Ozb/4YftNB0xMU5HqZRP0gQADDu3NbERISfnByr3yCN22mhdM6D+FRbC9Om23f6OO+zInY8/tlMzjBsHgYFOR6iUz9MEAIQGBTK2TyL/2XKAzJxjJ3c0b26bgBYsgK++ci5AX1JQYCde69ABJk2C+HiYO9cOvR0zRp+9UKoR6V+by019kzBgF4upaNIke5V6//22nVr9MkeO2E719u3tg3ZdusB//mMXWhk+XEfvKOUATQAuic3DGdw5jtkr0ykqKTu5IyQEnnoKNm+2DxupM/Pzz3aq7Xbt4MEH7eRrP/wA33wDQ4Zoxa+UgzQBVDAhJZmsvOPM37z/1B1XX22fLH30UXslq2qXlWUr/ORkeOwx+++3ciV8+SUMHOh0dEopNAGc4qKzW5LYvAnvLK3UGSxipw/IyrJTRajqZWbaJp7kZDuUdsQIWL8e/v1v6H3acyhKKQdpAqggMEC4qW8yy386zI4DeafuvOACmDDBdmDu3u1IfB4tLc32l7RvD9Omwdixdijn7Nl2vQWllMfRBFDJ2N4JhAQG8G7lIaFg548PCLBNG8rauNEO4+zY0faR3HYbbN8Ob75pn95VSnksTQCVxEaGMuK81ny8Zi8FxyuN+klMtM8EzJ4Ny5Y5E6AnSEuzzTvdu9snd997D37zG9i5006n3aGD0xEqpdygCaAKE/onk3e8hE/XVV72ALtoTOvWtp3bnx4OO3TIPrg1aJAd0TN1KkRG2mU09+yxzT6JibV+jFLKc2gCqEKvpGZ0bdOUd5alcdpsqZGRdpbQpUvho4+cCbCxFBTYaRlGjrQrpk2aBNnZ9vx37oQlS+x0GfW4UptSqvFoAqhC+WIxW/YdYc2enNMPuO022/zxwAN2SgNfUlxsn8y9+WaIi7Nr5q5fb1fRWrcONm2yU2RrM49SXk8TQDWu7hlPZGhQ1Z3BgYHwzDPw0092ZNC//20fePJWZWX24axJk+yV/pVX2qkvJkywayOkpdmH4Xr00Ae3lPIhfr8eQHUiQoO4plc8s1ek88jIbjSPqDT98GWXwZQpMHOmbQoSscsRDhkCgwfbtvKmTR2J3W0bN9opmN9/31byTZrA6NH2qv+KK3TKZaV8nFt3ACIyTES2iUiqiEytYr+IyDTX/g0i0qu2siLymIjsFZF1rteI+jml+jM+JZmi0jI+XJVe9QHPPmvnrf/+ezvdQXQ0vPCCbTNv3hxSUuyQ0fnzTy5b6LS0NDsnT/kInqefhm7d4J134OBBmwyuukorf6X8QK1LQopIILAdGApkYBd6v9EYs7nCMSOAe7DrAvcDnjPG9KuprIg8BuQbY/7ubrANsSRkbca+vJR9ucf49v7BBAS40fxx7JgdIvrNN7BwoV3GsKQEgoPt0oWDB9u7hJQUCAtrmKBLSmDfPjs6Z88eu47unj2wdq3tuAUYMMBe6Y8dq524Svm4uiwJ2RdINcbscn3QbGA0sLnCMaOBt12Lui8TkRgRaQO0c6OsR5uQksw976/l2x1ZDO4cV3uBJk1sJT94sH2fn29nvFy40CaFv/7VrnQVGmor4fImI3dXuTLG3nVUrtwrvjIzobT01HIxMfZhrb/+FW680T6xq5Tya+4kgHigYhtIBvYqv7Zj4t0oO1lEbgFWAfcZY07rSRWRicBEgKSkJDfCrV9XnNOaFpGhvLs0zb0EUFlkpG1Pv+IK+z431zYZld8hPPqordTDw22/QXn/QVHR6RV7eWWfn3/qzwgJgYQESEqy5ZOS7Jj8pKST30dF1f0fQynlU9xJAFW1e1RuN6rumJrKTgeecL1/AngG+NVpBxszE5gJtgnIjXjrVUhQAOP6JPLiolTSDx8lsXl43T4wOtr2EYwcad9nZ9uRNgsX2tfU07pYoFUrW4l36QKXX356BR8XpwupKKXOmDsJIAOo+IhnAlD5Ednqjgmprqwx5kD5RhF5Bfjc7agb2Y39knhpUSrvr9jDH4d1qd8Pj42Fa66xL4ADB2wfQlSUrdwTEhqur0Ap5dfcuWxcCXQSkfYiEgKMA+ZUOmYOcItrNFAKkGuM2VdTWVcfQbkxwMY6nkuDiY9pwpAurfhgZTrHS0prL1AXrVrZoZhDhtg2e638lVINpNYEYIwpASYD84AtwIfGmE0icpeI3OU6bC6wC0gFXgEm1VTWVeYpEflRRDYAg4Hf1d9p1b8J/ZPJLijiq437az9YKaW8QK3DQD2JE8NAy5WVGQY/s4i4qFD+edcAR2JQSqlforphoNpz6KaAAOHmfkms3P0zW/frspBKKe+nCeAMXH9BIiFB1SwWo5RSXkYTwBloFhHCyO5t+GTNXvIrLxajlFJeRhPAGZqQkkxBUSmfrN3rdChKKVUnmgDOUM/EGM5p25R3l1axWIxSSnkRTQBnSESYkJLMtgN5rErz4jUAlFJ+TxPALzCqZ1uiwoJ4Z6l2BiulvJcmgF8gPCSIa3sl8OXGfRzKP+50OEop9YtoAviFxqckU1xqeOX7XdoXoJTySpoAfqGOcZFc1aMtL3+7iz9+tIHC4gaeI0gppeqZrglcB8/e0JP2seFM+yaVjZlHmDG+F8mxEU6HpZRSbtE7gDoIDBB+f3lnXr+tN5k5xxj5/A8s2Hyg9oJKKeUBNAHUgyFdWvH5PReSHBvOf729iqe+2kpJaZnTYSmlVI00AdSTxObhfHTXAG7sm8hLi3Zyy+srdISQUsqjaQKoR2HBgfzvNd156rrurE77mSunfc/qtMNOh6WUUlXSBNAAxvZO5ONJAwgNCuSGl5fxxuKfdKioUsrjaAJoIOe0jeazey7kks4tefyzzdzz/loKdAZRpZQHcSsBiMgwEdkmIqkiMrWK/SIi01z7N4hIrzMoe7+IGBFpUbdT8TzRTYKZOaE3fxzWmbk/7mP0i4tJPZjndFhKKQW4kQBEJBB4ERgOdANuFJFulQ4bDnRyvSYC090pKyKJwFBgT53PxEMFBAiTLunIu3f04+eCIka9sJjPN2Q6HZZSSrl1B9AXSDXG7DLGFAGzgdGVjhkNvG2sZUCMiLRxo+z/AX8EfL6BfEDHFnzx20F0aR3F5PfW8vhnmygq0aGiSinnuJMA4oH0Cu8zXNvcOabasiIyCthrjFl/hjF7rdbRYcye2J/bB7bjjcW7ufGVZezPLXQ6LKWUn3InAUgV2ypfsVd3TJXbRSQceAh4tNYfLjJRRFaJyKqsrKxag/V0IUEB/Pmqc3j+xvPZsu8II5//niWph5wOSynlh9xJABlAYoX3CUDlRuzqjqlu+1lAe2C9iOx2bV8jIq0r/3BjzExjTG9jTO+WLVu6Ea53uKpHW+ZMHkh0k2DGv7aclxalUlbm8y1hSikP4k4CWAl0EpH2IhICjAPmVDpmDnCLazRQCpBrjNlXXVljzI/GmDhjTDtjTDtsouhljNlfXyfmDTrGRfHp5AsZcV4bnvpqGxPfWU3usWKnw1JK+YlaE4AxpgSYDMwDtgAfGmM2ichdInKX67C5wC4gFXgFmFRT2Xo/Cy8WGRrE8zeez5+v6saibQcZ9cIPbMrMdTospZQfEG96QrV3795m1apVTofRYFanHWbSrDXkHC3mqeu6M7pn5b52pZQ6cyKy2hjTu/J2fRLYg1yQ3JwvfjuIHokxTJm9jqfnbdV+AaVUg9EE4GFaRIby7h39GNcnkRcX7uQ3s1ZztEinkFBK1T9NAB4oJCiA/73mPB4Z2Y0Fmw9w3fSlZOYcczospZSP0QTgoUSEOy5sz2u39WHP4aOMemExa/f87HRYSikfognAww3uHMfHkwbQJCSAG2Yu49N1e50OSSnlIzQBeIGzW0Xx6d0X0tPVOfz3edu0c1gpVWeaALxE84gQ3r2jHzf0TuSFhalMmrVGO4eVUnWiCcCLhAQF8OS1tnN4/ub9XD9DO4eVUr+cJgAvU7FzOC37KKNf1M5hpdQvownAS5V3DocFa+ewUuqX0QTgxSp3Dj8zXzuHlVLu0wTg5Sp2Dj//TSp3v6edw0op92gC8AHlncMPX9mVeZu0c1gp5R5NAD5CRPj1oA68dqt2Diul3KMJwMcM7qKdw0op92gC8EHaOayUcocmAB+lncNKqdpoAvBhlTuHr52+lO+2Z+FNq8AppRqOWwlARIaJyDYRSRWRqVXsFxGZ5tq/QUR61VZWRJ5wHbtOROaLSNv6OSVVUcXO4cMFx7nl9RWMmPYDn67bS0lpmdPhKaUcVOuawCISCGwHhgIZwErgRmPM5grHjADuAUYA/YDnjDH9aiorIk2NMUdc5X8LdDPG3EUNfH1N4IZ2vKSUT9dlMvO7XaQezCc+pgm/HtSeG/okEh4S5HR4SqkGUpc1gfsCqcaYXcaYImA2MLrSMaOBt421DIgRkTY1lS2v/F0iAG2XaGChQYGM7Z3I/Hsv4tVbetM2JozHP9vMgCe/4R/zt3Eo/7jTISqlGpE7l33xQHqF9xnYq/zajomvrayI/BW4BcgFBlf1w0VkIjARICkpyY1wVW0CAoTLurXism6tWJ12mJe/3cXzC1N5+btdXN87gV9f2IF2LSKcDlMp1cDcuQOQKrZVvlqv7pgayxpjHjLGJAKzgMlV/XBjzExjTG9jTO+WLVu6Ea46ExckN2fmLb1Z8LuLGXN+PB+uzGDIM4u4e9Ya1qfnOB2eUqoBuZMAMoDECu8TgEw3j3GnLMB7wLVuxKIaSMe4SJ68tjs/PDCYOy8+i+92ZDH6xcXcOHMZi7Yd1JFDSvkgdxLASqCTiLQXkRBgHDCn0jFzgFtco4FSgFxjzL6ayopIpwrlRwFb63guqh7ENQ3jgWFdWDJ1CA+N6MpPhwq47Y2VDH/uez5Zm0GxjhxSymfUOgoITozyeRYIBF43xvxVRO4CMMbMEBEBXgCGAUeB240xq6or69r+L6AzUAakAXcZY2qct0BHATW+opIy5qzPZOZ3O9l+IJ+20WHcMagD4/okEhGqI4eU8gbVjQJyKwF4Ck0AzikrMyzafpCXv93F8p8O0zQsiFv6t+PWAe1oGRXqdHhKqRpoAlD1Zu2en3n5213M27yf4MAALjm7Ja2ahhEbGUJsRAixkaE0jwihRWQIzSNCiWkSTEBAVeMBlFKNoboEoPfw6oydn9SMGRMuYFdWPq/+8BPLdmaz/KfD5B4rrvL4wAChWXgwsRE2MVSXKMq3Nw3ThKFUY9AEoH6xDi0j+Z8x5514X1xaxs9Hi8jOL+JwQRGH8o9zuMC+zy4oItv1flPmEbLzj3OksOrJ6QIDhOYRIVx5XhumDu9CWHBgY52SUn5FE4CqN8GBAcRFhREXFebW8UUlJxNGdsFxV9Io4nDBcXZnH+XNJbtZsvMQz9/Yi86toxo4eqX8jyYA5ZiQoABaNQ2jVdOqE8bY3lnc9+F6Rr3wAw9f2ZXxKcnYAWdKqfqg00Erj3Xx2S356t5BpHSI5ZFPNzHxndX8XFDkdFhK+QxNAMqjtYgM5Y3b+vDwlV1ZtO0gw577jiU7DzkdllI+QROA8ngBAXZNg08mDSQiJIibX13O0/O26lPJStWRJgDlNc6Nj+azey7k+gsSeHHhTsa+vJT0w0edDkspr6UJQHmViNAgnrquB8/feD6pB/IZ8dz3fLquxhlElFLV0ASgvNJVPdoyd8ogOrWKZMrsddz/z/UUHNdF75U6E5oAlNdKbB7Oh3f257dDOvKvNRmMfP4HfszIdTospbyGJgDl1YICA/j95Z15/79SKCwu5Zrpi5n53U7KyrxnjiulnKIJQPmElA6xfDllEEO6xPE/c7dy6xsrOJhX6HRYSnk0TQDKZ8SEhzBj/AX85epzWfHTYUY89z0Ltx10OiylPJYmAOVTRITxKcl8ds+FxEaEcvsbK/nvzzZzvKTU6dCU8jiaAJRPOrtVFJ9OHsgt/ZN5ffFPjHlxCTuz8p0OSymP4lYCEJFhIrJNRFJFZGoV+0VEprn2bxCRXrWVFZGnRWSr6/hPRCSmXs5IKZew4ED+e/S5zJxwAZm5xxg57Qc+WLmHUu0gVgpwY0UwEQkEtgNDgQzsQu83GmM2VzhmBHAPMALoBzxnjOlXU1kRuRz4xhhTIiJ/AzDGPFBTLLoimPql9ucW8rsP1rF0VzYRIYGcGx9Nz8QYuifE0CMxmviYJjrTqPJZdVkRrC+QaozZ5fqg2cBoYHOFY0YDbxubTZaJSIyItAHaVVfWGDO/QvllwHVnflpKuad1dBjv/rofX/y4j1W7D7M+I5c3Fu+myDWfUIvIEJsMEmLonhhNj4QYmkeEOBy1Ug3LnQQQD6RXeJ+Bvcqv7Zh4N8sC/Ar4oKofLiITgYkASUlJboSrVNUCA4RRPdoyqkdbAI6XlLJtfx7r03NYl57LhowcFm47SPlNcVLzcLonnLxTODe+KeEhuoSG8h3u/DZXdV9cud2oumNqLSsiDwElwKyqfrgxZiYwE2wTUG3BKuWu0KBAuifYyn1Cf7str7CYjXuPsD4jh/XpOazdk8PnG/YBECC2c7lHQgw9Em3T0dmtoggO1LEUyju5kwAygMQK7xOATDePCamprIjcCowELjW1dUYo1QiiwoLpf1Ys/c+KPbEtK+84G1wJYX1GLvM27+eDVfbGNjQogHPjozmnbVPaxjShVdNQWjUNo3XTMFpHh+kdg/Jo7vx2rgQ6iUh7YC8wDrip0jFzgMmuNv5+QK4xZp+IZFVXVkSGAQ8AFxtjdE5f5bFaRoVyaddWXNq1FQDGGPYcPsr6jFzWp+ewISOHj9fsJb+KyeiiQoNoFW0TQlzT0BOJIS7Kfm3dNIwWkSEE6V2EckCtCcA1SmcyMA8IBF43xmwSkbtc+2cAc7EjgFKBo8DtNZV1ffQLQCiwwDX6Ypkx5q76PDmlGoKIkBwbQXJsxIn+BID84yUcOFLIgdxC9h8p5MCR4xw4Usj+3EIO5BWybGc+B/OOU1JpGGqA2JXPTiaGUFfCCOOctk05p210Y5+i8hO1DgP1JDoMVHm7sjJDdkHRKYnhtIRxpJCco8UnyvRMjOHWAcmMOK8NoUGBDkavvFV1w0A1ASjlgQqLSzlwpJCFWw/y9tI0dh0qIDYihHF9E7m5XzJtY5o4HaLyIpoAlPJSZWWGxTsP8fbSNP6z5QAAl3drzS0DkunfIVYfYFO1qsuDYEopBwUECIM6tWRQp5akHz7KrOV7+GDlHr7atJ9OcZHc0j+ZMb0SiAzVP2d1ZvQOQCkvVFhcymfrM3l7aRo/7s0lMjSIa3vFM6F/OzrGRTodnvIw2gSklA8yxrAuPYe3l6bxxYZ9FJWWcWHHFtzSP5lLu7YiMECbh5QmAKV8XlbecT5YuYdZy/ewL7eQ+Jgm3JySxLg+STqvkZ/TBKCUnygpLePrLQd4a0kaS3dlExIUwFXd23LrgGS6J8Q4HZ5ygCYApfzQ9gN5vL10Nx+v2cvRolJ6JMZwa/9kLuvWiqZhwU6HpxqJJgCl/NiRwmI+Xp1x4pkCgLbRYZzdOorOraPo3CqKs1tF0TEukrBgfdjM12gCUEpRVmZY/tNh1qb/zPb9eWzdn8fOrHyKS209ECDQrkUEXVrbhNC5lU0QybER2qHsxfQ5AKUUAQFy2mynxaVlpGUXsHV/3omksDnzCF9u3H9ibYTQoAA6xkWevFtoHUWX1lG0bhqmD6J5MU0ASvm54MAAOsZF0TEuCrqf3H6sqJQdB/PYtj+P7QdsYliceoiP1+w9cUxUWNCJu4SzW0XRIjKUmPBgopsEExMeTEx4CBEhgZokPJQmAKVUlZqEnFwwp6Kco0UnksK2AzZBfLY+kyOFp0+HDRAUIEQ3CSY6PJiYJuXJIeRkkjixL+TEMTHhITQNC9JpshuYJgCl1BmJCQ+hX4dY+nU42YxkjCEr/zg/FxSTc7SInGPF5B4rJvdoMTnHisg5WkzOsWKOHCvmUH4RqVn55BwtJq+apFEuKjSIllGhnBsfTY/EGHomRnNO22jtqK4nmgCUUnUmIsRF2fUMzkRJaRl5hSXkHKuQOI7a5JHjSh6ZOcdYtfswc9bbxQSDAoTOraNsQnAtz9kxLlI7qX8BTQBKKccEBQbQLCKEZhEhQESNxx48UnhiFbb1GTl8tj6T95bvASA8JJDz4qPpmVi+XnMMbaO1g7o2mgCUUl4hrmkYQ7uFMbSbXZqzrMywO7uA9Rk5rE/PZV16Dm8s3k1RaRlgV1nrmRhND9ddQo+EGKLD9eG3itxKAK71e5/DLuv4qjHmyUr7xbV/BHZJyNuMMWtqKisi1wOPAV2BvsYYHeCvlHJbQIDQoWUkHVpGMub8BACKSsrYuv8I69NzWJeey/qMHL7ecvBEmfYtIuiRYPsTOsVF0TwihOYRITSLCPbL1dZqTQAiEgi8CAwFMoCVIjLHGLO5wmHDgU6uVz9gOtCvlrIbgWuAl+vxfJRSfiwkKODEyKUJ/e22I4XFbMzIZV1GDuvTc1i26zD/Xpd5WtmIkECaR4bQPNw2STUPL08Orq/hIcRG2q/NI+woJm/vd3DnDqAvkGqM2QUgIrOB0UDFBDAaeNvYx4qXiUiMiLQB2lVX1hizxbWtvs5FKaVO0zQsmAEdWzCgY4sT2/bnFrLn8FEOFxTx89EiDhfY188FRWS7vk89mM/PBUUUFJVW+bkBYkdENQsPPiVBhIcEERYcQGhQIGHBAYQFBxIWFEhohW2n7AsOJDSo/Hu7r7ESizsJIB5Ir/A+A3uVX9sx8W6WVUqpRtU6OozW0e6NWCosLj2RJH4uKCa74Dg/FxRx+Gix/ep67Tl8lLXpORwrKqWwuJSSsl8+zU5woLiSRnlyCOB/xpx3ytDb+uBOAqgqFVU+s+qOcadszT9cZCIwESApKelMiiqlVJ2FBQfSJroJbaKbnFG5ktIyCkvKOF5cSmFJGYXFNjEcd31/vNi1raTi92WnHFNYbMsfLykjqgFmb3UnAWQAiRXeJwCVG9CqOybEjbI1MsbMBGaCnQzuTMoqpZRTggIDiAwM8Oi1mt15znol0ElE2otICDAOmFPpmDnALWKlALnGmH1ullVKKeWAWlOTMaZERCYD87BDOV83xmwSkbtc+2cAc7FDQFOxw0Bvr6ksgIiMAZ4HWgJfiMg6Y8wV9X2CSimlqqbrASillI+rbj0AnWpPKaX8lCYApZTyU5oAlFLKT2kCUEopP6UJQCml/JRXjQISkSwg7RcWbwEcqsdwGpo3xetNsYJ3xetNsYJ3xetNsULd4k02xrSsvNGrEkBdiMiqqoZBeSpvitebYgXvitebYgXvitebYoWGiVebgJRSyk9pAlBKKT/lTwlgptMBnCFvitebYgXvitebYgXvitebYoUGiNdv+gCUUkqdyp/uAJRSSlWgCUAppfyUXyQAERkmIttEJFVEpjodT3VEJFFEForIFhHZJCJTnI6pNiISKCJrReRzp2OpjWut6o9EZKvr37i/0zHVRER+5/o92Cgi74uIe2sYNgIReV1EDorIxgrbmovIAhHZ4frazMkYK6om3qddvwsbROQTEYlxMMQTqoq1wr77RcSISIuqyp4pn08AIhIIvAgMB7oBN4pIN2ejqlYJcJ8xpiuQAtztwbGWmwJscToINz0HfGWM6QL0wIPjFpF44LdAb2PMudj1NMY5G9Up3gSGVdo2FfiPMaYT8B/Xe0/xJqfHuwA41xjTHdgOPNjYQVXjTU6PFRFJBIYCe+rrB/l8AgD6AqnGmF3GmCJgNjDa4ZiqZIzZZ4xZ4/o+D1tBxTsbVfVEJAG4EnjV6VhqIyJNgYuA1wCMMUXGmBxHg6pdENBERIKAcM5wOdWGZIz5DjhcafNo4C3X928BVzdmTDWpKl5jzHxjTInr7TLskrWOq+bfFuD/gD9yhuuq18QfEkA8kF7hfQYeXKmWE5F2wPnAcodDqcmz2F/IMofjcEcHIAt4w9Vk9aqIRDgdVHWMMXuBv2Ov9vZhl1md72xUtWrlWgoW19c4h+M5E78CvnQ6iOqIyChgrzFmfX1+rj8kAKlim0ePfRWRSOBfwL3GmCNOx1MVERkJHDTGrHY6FjcFAb2A6caY84ECPKuJ4hSu9vPRQHugLRAhIuOdjco3ichD2ObXWU7HUhURCQceAh6t78/2hwSQASRWeJ+AB91KVyYiwdjKf5Yx5mOn46nBQGCUiOzGNqsNEZF3nQ2pRhlAhjGm/I7qI2xC8FSXAT8ZY7KMMcXAx8AAh2OqzQERaQPg+nrQ4XhqJSK3AiOBm43nPhR1FvZCYL3r7y0BWCMirev6wf6QAFYCnUSkvYiEYDvS5jgcU5VERLBt1FuMMf9wOp6aGGMeNMYkGGPaYf9NvzHGeOwVqjFmP5AuIp1dmy4FNjsYUm32ACkiEu76vbgUD+60dpkD3Or6/lbgUwdjqZWIDAMeAEYZY446HU91jDE/GmPijDHtXH9vGUAv1+90nfh8AnB18kwG5mH/gD40xmxyNqpqDQQmYK+m17leI5wOyofcA8wSkQ1AT+B/nA2neq47lY+ANcCP2L9Vj5m6QETeB5YCnUUkQ0TuAJ4EhorIDuxolSedjLGiauJ9AYgCFrj+1mY4GqRLNbE2zM/y3LsepZRSDcnn7wCUUkpVTROAUkr5KU0ASinlpzQBKKWUn9IEoJRSfkoTgFJK+SlNAEop5af+H6AgTXNhcL1iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(loss_log_rain)\n",
    "plt.plot(loss_log_test,'r')\n",
    "plt.legend(['train','test'])\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-contents",
   "metadata": {},
   "source": [
    "## 小結論\n",
    "<font size=4>\n",
    "模型如果越複雜，資料的變異不夠，越容易產生overfitting的問題。<br>\n",
    "先不管training tricks的方式來避免overfitting的問題。<br>\n",
    "最簡單的方式就是前面07_pytorch_classification_DataAugumentionImprove.ipynb範例，利用資料增強的方式，增加資料的變異避免overfitting的問題發生。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-setup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
