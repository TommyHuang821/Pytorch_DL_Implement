{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輔助 02_pytorch_dataloader 在Windows不能執行的問題，此篇結果是在linux執行得到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total data:4597\n",
      "torch.Size([10, 3, 224, 224])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import torchvision.transforms.functional as FT\n",
    "from torchvision import transforms\n",
    "\n",
    "import json\n",
    "__author__ = \"Chih-Sheng(Tommy) Huang\"\n",
    "\n",
    "mytransform=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "class MyDataset_CarBrandsImages(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Class to load the dataset\n",
    "    '''\n",
    "    def __init__(self,transforms):\n",
    "        \n",
    "        with open('./dataset/kaggle/CarBrandsImages/carbrand.json') as jsonfile:\n",
    "            data_load = json.load(jsonfile)\n",
    "        self.imList = data_load['imagepaths']\n",
    "        self.labelList = data_load['labels']\n",
    "        self.transforms=transforms\n",
    "        print('number of total data:{}'.format(len(self.imList)))\n",
    "    def __len__(self):\n",
    "        return len(self.imList)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        :param idx: Index of the image file\n",
    "        :return: returns the image and corresponding label file.\n",
    "        '''\n",
    "        image_name = self.imList[idx]\n",
    "        label = self.labelList[idx]\n",
    "        \n",
    "        # read image with PIL module\n",
    "        image = Image.open(image_name, mode='r')\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # Convert PIL label image to torch.Tensor\n",
    "        image = self.transforms(image)\n",
    "        label = torch.tensor(label)\n",
    "        return image, label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mydataset = MyDataset_CarBrandsImages(transforms=mytransform)\n",
    "    mydata_loader = torch.utils.data.DataLoader(mydataset, batch_size=10, num_workers=0)\n",
    "    for data, target in mydata_loader:\n",
    "        print(data.size())\n",
    "        print(target.size())\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total data:4597\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([97])\n"
     ]
    }
   ],
   "source": [
    "def my_collate(batch):\n",
    "    data, target = list(), list()\n",
    "    for b in batch:\n",
    "        data.append(b[0])\n",
    "        target.append(b[1])\n",
    "    data = torch.stack(data,dim=0)\n",
    "    target = torch.stack(target,dim=0)\n",
    "    return data, target\n",
    "mydataset = MyDataset_CarBrandsImages(transforms=mytransform)\n",
    "mydata_loader = torch.utils.data.DataLoader(mydataset, batch_size=100, num_workers=3, collate_fn = my_collate)\n",
    "for data, target in mydata_loader:\n",
    "    print(target.size())\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **這邊我們測試看看如果需要讀圖檔下，開不開workers差多少。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total data:4597\n",
      "\n",
      " num_workers: 0\n",
      "total iteration: 192, a forloop time for whole dataset within CPU: 6.560382127761841s\n",
      "\n",
      " num_workers: 2\n",
      "total iteration: 192, a forloop time for whole dataset within CPU: 3.8272275924682617s\n",
      "\n",
      " num_workers: 4\n",
      "total iteration: 192, a forloop time for whole dataset within CPU: 2.1363651752471924s\n",
      "\n",
      " num_workers: 8\n",
      "total iteration: 192, a forloop time for whole dataset within CPU: 1.7824933528900146s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mydataset = MyDataset_CarBrandsImages(transforms=mytransform)\n",
    "\n",
    "def fun_timetest(data_loader):\n",
    "    start = time.time()\n",
    "    count=0\n",
    "    for data, target in data_loader:\n",
    "        count+=1\n",
    "    timeimplement = time.time()-start\n",
    "    print(\"total iteration: {}, a forloop time for whole dataset within CPU: {}s\".format(count, timeimplement) )\n",
    "    return timeimplement\n",
    "\n",
    "for i in [0, 2, 4, 8]:\n",
    "    mydata_loader = torch.utils.data.DataLoader(mydataset, batch_size=24, num_workers=i)\n",
    "    print(\"\\n num_workers: {}\".format(i))\n",
    "    timeimplement = fun_timetest(mydata_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
